<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Connectionist Temporal Classification · Shayue'Log</title><meta name="description" content="Connectionist Temporal Classification - wangt"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/images/waterlemon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="https://shayue111.github.io/atom.xml" title="Shayue'Log"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="Shayue'Log" type="application/atom+xml">
</head><body><header><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">HOME</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="/categories/" target="_self" class="nav-list-link">CATEGORY</a></li><li class="nav-list-item"><a href="/tags/" target="_self" class="nav-list-link">TAG</a></li><li class="nav-list-item"><a href="/about/" target="_self" class="nav-list-link">ABOUT</a></li></ul></header><main class="container"><script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    }
});</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});</script><script async type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><div class="post"><article class="post-block"><h1 class="post-title">Connectionist Temporal Classification</h1><div class="post-info">Dec 15, 2020<a href="/tags/Text-Recognition/" class="tag-title"># Text Recognition</a><a href="/tags/Loss/" class="tag-title"># Loss</a></div><div class="post-content"><blockquote>
<p>由于需要进行图片文本识别相关的工作，最近接触到了CTC Loss，打算将这几天的学习进行归纳总结。如果有接触过<code>HMM</code>的相关内容，看到<code>CTC</code>可能会觉得很亲切。</p>
</blockquote>
<a id="more"></a>
<h2 id="1-前言">1. 前言</h2>
<p>如果想要识别图片中的文字，神经网络是一个不错的选择，它们在大多数情况下表现良好。一般来说，用于文本识别工作的神经网络会用到<code>convolutional layers</code>和<code>recurrent layers</code>，前者常被用于提取图片中的特征并送入后者。后者的输出是一个矩阵，存放着每个时间步中属于某个字符的概率。基于CRNN架构的文字识别如下图所示，</p>
<p><img src="/images/ObjectDetection/CTC.png" alt="CRNN Overview"></p>
<center style="font-size:14px;color:#C0C0C0">Figure1, CRNN Overview</center>
<p>要训练这样的网络，可以设想一下最通俗的做法，那就是字符级别的分类识别。比如对于上图来说，同时需要标注图片中每个字符的位置，比如图片中<code>A</code>所在的位置，然后这个部分对应的字符是<code>A</code>，依次类推，对这张图片里的其他字符还需要做同样标注行为。对于图片，这样标注仅仅只是耗时，但是有些任务比如语音识别，甚至无法标注字符出现的位置。</p>
<p>为了解决上述难题，<a target="_blank" rel="noopener" href="https://www.cs.toronto.edu/~graves/icml_2006.pdf">CTC</a>被提出了，它是一种能让RNN直接利用图片数据或语音数据与文本数据进行端到端训练的方法。</p>
<h2 id="2-对齐">2. 对齐</h2>
<p>不标注字符的具体位置，对于像图片数据转文字或者语音数据转文字的任务，会存在一个问题，那就是如何将输入与输出<code>对齐</code>。</p>
<p>拿图片来说，输入图片经过CNN后转化得到特征向量，将这些特征组成序列输入RNN。为了方便，RNN的序列步长<code>T</code>是固定的，相应的，RNN的输出也是<code>T</code>。但是，我们不能保证数据集<code>&lt;X, Y&gt;</code>中的文字长度都是<code>T</code>，RNN的输入与标签   <code>y</code>可能无法对齐。比如在图片<code>Figure1</code>中，设<code>T = 10</code>，而目标单词<code>Available</code>的长度只有9，此时就无法对齐。</p>
<p>为了解决对齐问题，为<code>Figure1</code>增加<code>CTC Layer</code>，加在RNN输出之后。</p>
<p><img src="/images/ObjectDetection/CTC_decoder.png" alt="CRNN Overview"></p>
<center style="font-size:14px;color:#C0C0C0">Figure2, CRNN with decoder</center>
<p>如<code>Figure2</code>所示，设RNN输出的步长固定为10。当$y_i$的长度不足10时，允许RNN能在相邻位置上预测出相同的字符。在<code>CTC layer</code>中解码时，将相邻相同的字符合并即可。</p>
<p>但是，又来了一个问题，如果$y_i == hello$，即标签中相邻位置本就存在相同字符，上述的解码策略就行不通了。为此，再引入一个特殊字符$\epsilon$，称作<code>blank token</code>，在解码的时候去掉。如果RNN序列长度还是10，那么比如RNN输出路径为$h e l \epsilon l \epsilon o o o o$，是能被解码到<code>hello</code>的。</p>
<p>总结来说，为了能够解决<strong>对齐问题</strong>，我们在<code>RNN layer</code>后加了<code>CTC layer</code>，并且为<code>RNN</code>的字符分类增加新的一类$\epsilon$。根据相应的解码规则，期待<code>RNN</code>的输出在经过<code>CTC</code>的转化后能得到正确路径。更加具体的解码细节，会放在<code>第4部分概率计算</code>中介绍。</p>
<h2 id="3-目标函数">3. 目标函数</h2>
<p>终于来到本文的重点，这一部分将介绍<code>CTC Loss</code>。</p>
<p>到现在为止，我们知道RNN要处理的是多对多的多分类问题，它需要将输入的特征序列转化为序列矩阵。矩阵的每一行是字符所对应的类别，矩阵的每一列是所处的时间步。</p>
<h4 id="3-1-概率">3.1. 概率</h4>
<p>为了更加形象，下面以具体的任务进行举例。假设待预测的图片只包括<code>我爱学习</code>4个字，<code>RNN</code>在每个时间步需要预测的字符也仅有5类$\{我，爱，学，习，\epsilon\}$，RNN的序列步长固定为5。那么RNN的一次输出可能产生如下矩阵：</p>
<table>
<thead>
<tr>
<th style="text-align:center"></th>
<th style="text-align:center">$step_1$</th>
<th style="text-align:center">$step_2$</th>
<th style="text-align:center">$step_3$</th>
<th style="text-align:center">$step_4$</th>
<th style="text-align:center">$step_5$</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center"><strong>我</strong></td>
<td style="text-align:center">0.469</td>
<td style="text-align:center">0.202</td>
<td style="text-align:center">0.244</td>
<td style="text-align:center">0.011</td>
<td style="text-align:center">0.154</td>
</tr>
<tr>
<td style="text-align:center"><strong>爱</strong></td>
<td style="text-align:center">0.043</td>
<td style="text-align:center">0.217</td>
<td style="text-align:center">0.211</td>
<td style="text-align:center">0.314</td>
<td style="text-align:center">0.185</td>
</tr>
<tr>
<td style="text-align:center"><strong>学</strong></td>
<td style="text-align:center">0.249</td>
<td style="text-align:center">0.179</td>
<td style="text-align:center">0.207</td>
<td style="text-align:center">0.152</td>
<td style="text-align:center">0.204</td>
</tr>
<tr>
<td style="text-align:center"><strong>习</strong></td>
<td style="text-align:center">0.144</td>
<td style="text-align:center">0.13</td>
<td style="text-align:center">0.137</td>
<td style="text-align:center">0.296</td>
<td style="text-align:center">0.227</td>
</tr>
<tr>
<td style="text-align:center"><strong>$\epsilon$</strong></td>
<td style="text-align:center">0.096</td>
<td style="text-align:center">0.272</td>
<td style="text-align:center">0.2</td>
<td style="text-align:center">0.227</td>
<td style="text-align:center">0.231</td>
</tr>
</tbody>
</table>
<p>每一个时间步，所有字符出现的概率和为1。下面，可以通过这个矩阵计算出解码层最后输出<code>我爱学习</code>的概率。首选需要列出所有可能解码出<code>我爱学习</code>的路径，但是值得一提的是，实际的解码过程中并不会通过这种穷举方法得到需要的概率，因为计算量非常的大。</p>
<p><strong>路径：</strong></p>
<ol>
<li>$\epsilon$ -&gt; 我 -&gt; 爱 -&gt; 学 -&gt; 习</li>
<li>我 -&gt; $\epsilon$ -&gt; 爱 -&gt; 学 -&gt; 习</li>
<li>我 -&gt; 爱 -&gt; $\epsilon$ -&gt; 学 -&gt; 习</li>
<li>我 -&gt; 爱 -&gt; 学 -&gt; $\epsilon$ -&gt; 习</li>
<li>我 -&gt; 爱 -&gt; 学 -&gt; 习 -&gt; $\epsilon$</li>
<li>我 -&gt; 我 -&gt; 爱 -&gt; 学 -&gt; 习</li>
<li>我 -&gt; 爱 -&gt; 爱 -&gt; 学 -&gt; 习</li>
<li>我 -&gt; 爱 -&gt; 学 -&gt; 学 -&gt; 习</li>
<li>我 -&gt; 爱 -&gt; 学 -&gt; 习 -&gt; 习</li>
</ol>
<p>上面列出了所有能得到正确解码序列的路径，共有9条。路径数量会受到RNN序列长度、标签文字长度以及标签文字中重复字符的个数的影响，而且是指数级别的增长。</p>
<p>接下来，需要分别计算上述路径的概率，之后再求和，即可得到模型输出<code>我爱学习</code>的概率。</p>
<p>\begin{equation}<br>
\tag{1}<br>
p(我爱学习|x) = \sum_{j=1}^{m=9} p(path^j|x) = \sum_{j=1}^{9} (\prod_{t=1}^5 p(z_t^j|x))<br>
\end{equation}</p>
<h4 id="3-2-最大似然估计">3.2. 最大似然估计</h4>
<blockquote>
<p>参数的概率估计问题总是绕不过<code>MLE</code>。</p>
</blockquote>
<p>前面已经以计算$p(我爱学习|x)$作为概率计算的举例。假定现在有一组数据集，包括$N$组图片与文字$\left&lt;x_n, y_n\right&gt;$的对应关系，记作$\left&lt;X, Y\right&gt;$。同样的，分别计算出这些样本产出的概率（再次强调，不会穷举计算，具体算法文章之后会介绍），得到若干组概率$p(y_n|x_n)$。</p>
<p>根据极大似然的思想，<strong>好的模型，或者说好模型的参数</strong>会令似然函数最大，希望根据下式得到模型的参数（为了书写简便$\theta$有时省略），有：</p>
<p>\begin{equation}<br>
\tag{2}<br>
\theta^* = \underset{\theta}{\mathrm{argmin}} \prod_{n=1}^N  p(y_n|x_n, \theta)<br>
\end{equation}</p>
<p>到这里，我们就得到了<code>CTC Loss</code>的目标函数(Objective function)，如下所示：</p>
<p>\begin{equation*}<br>
\tag{3}<br>
\label{a}<br>
\max \prod_{n=1}^N  p(y_n|x_n) \iff \max \sum_{n=1}^N \log p(y_n|x_n) \<br>
\iff \min -\sum_{n=1}^N  \log p(y_n|x_n)<br>
\end{equation*}</p>
<p>如$\eqref{a}$式所示，目标是<code>最小化negative log-likelihood</code>。</p>
<h2 id="4-概率计算">4. 概率计算</h2>
<p>在<code>3.1</code>中我们用穷举的方法列出了所有能得到文本<code>我爱学习</code>的可能路径，下面将介绍<code>CTC</code>的另一个核心部分，即如何优化概率计算算法。</p>
<p>CTC中用到概率计算算法与HMM的前向-后向算法很像，论文中称作<code>CTC Forward-Backward Algorithm</code>，下面以该称呼指代。前向-后向算法关注的点在于如何利用相邻时间步状态的关系简化计算量。</p>
<p>论文给出前向概率的定义如下：</p>
<p>\begin{equation}<br>
\tag{4}\label{b}<br>
p(y_1, y_2, \cdots, y_s|x) = \alpha_{t}(s) \stackrel{def}{=} \sum_{\pi \in N^{T}: \atop \mathcal{B}\left(\pi_{1:t}\right)=label_{1:s}} {} \prod_{t^{\prime}=1}^{t} y_{\pi_{t^{\prime}}}^{t^{\prime}}<br>
\end{equation}</p>
<p>其中：</p>
<ul>
<li>$\pi$是单条可能的路径，$N^{T}$是所有的路径，$T$是RNN的输入(输出)步长；</li>
<li>$\mathcal{B}$是解码的规则，就像前面说的那样，<code>删除重复字符</code>与<code>去除blank token</code>；</li>
<li>$t$代表路径中的第几个时间步，$s$代表标签的第几个字符。</li>
</ul>
<p>总体来说，$\eqref{b}$看起来非常抽象，下面结合实际的标注文本：$我爱学习$</p>
<p>假定将RNN的输出步长$T$固定为10。现在需要计算第2个字符<code>爱</code>在时间步为5时的前向概率，那么可以写作$\alpha_{5}(\text{爱})$。为了更加清楚，在定义上加上字符的位置信息，写作$\alpha_{5}(label_2=\text{爱})$</p>
<p>此时，$label_{1:s}$就是$label_{1:2}$：$我爱$。我们需要找到所有的$\pi$，使得 $\mathcal{B}(\pi_{1:5}) == 我爱$。</p>
<p>比如，其中符合要求的路径$\pi$可以是：</p>
<ul>
<li>$\epsilon \rightarrow \epsilon \rightarrow 我 \rightarrow \epsilon \rightarrow 爱 \rightarrow \cdots$</li>
<li>$\epsilon \rightarrow 我 \rightarrow 我 \rightarrow \epsilon \rightarrow 爱 \rightarrow \cdots$</li>
<li>$\epsilon \rightarrow 我 \rightarrow \epsilon \rightarrow 爱 \rightarrow 爱 \rightarrow \cdots$</li>
<li>$\cdots$</li>
</ul>
<p>如上所示，虽然规定路径的长度为10，但由于需要的时间步$t$只有5，仅考虑前5个字符组合之后，符合解码需求的路径。</p>
<h4 id="4-1-前向算法">4.1. 前向算法</h4>
<p>下面先用一张图来介绍前向过程中「字符的流动」。</p>
<p><img src="/images/ObjectDetection/CTC_forward.png" alt="CTC Forward"></p>
<center style="font-size:14px;color:#C0C0C0">Figure3, CTC Forward</center>
<p>需要注意的这张图并不是RNN的输出矩阵，实际的输出矩阵还是只有5行，「我，爱，学，习，$\epsilon$」。这里只是为了让前向过程的状态转变更好理解，所以做了添加$\epsilon$的操作。</p>
<p>$\epsilon$在图中用<code>-</code>表示。我们先是将$\epsilon$分别插入文本的头尾以及内部，然后从左上到右下，将所有可能得到$我爱$的路径画了出来。</p>
<p>为了契合上面的变化，对于文本也做相应的变化：$$label「我爱学习」\rightarrow label^{\prime} 「\epsilon我\epsilon爱\epsilon学\epsilon习\epsilon」$$</p>
<p>要获取$\alpha_{5}(label_2=\text{爱})$，可以利用公式(5)：</p>
<p>\begin{equation}<br>
\tag{5}<br>
\alpha_{5}(label_2=\text{爱}) = \alpha_{5}(label^{\prime}_ 4=\text{爱}) + \alpha_{5}(label^{\prime}_5=\epsilon)<br>
\end{equation}</p>
<p>而，<br>
\begin{equation}<br>
\begin{aligned}<br>
\alpha_{5}(label^{\prime}_ 4=\text{爱}) &amp;= \left(\alpha_{4}(label^{\prime}_ 4=\text{爱}) + \alpha_{4}(label^{\prime}_ 3=\epsilon) + \alpha_{4}(label^{\prime}_ 2=\text{我})\right) * p(label^{\prime}=\text{爱}) \\<br>
\alpha_{5}(label^{\prime}_ 5=\epsilon) &amp;= \left(\alpha_{4}(label^{\prime}_ 5=\epsilon) + \alpha_{4}(label^{\prime}_ 4=\text{爱})\right) * p(label^{\prime}=\epsilon)<br>
\end{aligned}<br>
\end{equation}</p>
<br>
<p>当第$s$个$label^{\prime}$是$\epsilon$时，有两个转换来源；当是普通字符时，有三个转换来源。<strong>还有一个要注意的是，当相邻两个字符是相同的时候，也只有两个转换来源</strong>。如下图：</p>
<p><img src="/images/ObjectDetection/CTC_forward2.png" alt="CTC Forward2"></p>
<center style="font-size:14px;color:#C0C0C0">Figure4, CTC Forward 2</center>
<p>这样，我们可以写出针对$label^{\prime}$的转换方程，为了简写，用$l$代替$label$：</p>
<p>\begin{equation}<br>
\alpha_t(l^{\prime}_s)=<br>
\begin{cases}<br>
\left[\alpha _{t-1}(l^{\prime}_s) + \alpha _{t-1}(l^{\prime} _{s-1})\right] * p(l^{\prime}_s), \ \ if \ \ l^{\prime}_s=\epsilon \ \ or \ \ l^{\prime}_s=l^{\prime} _{s-2}<br>
\\<br>
\\<br>
\left[\alpha _{t-1}(l^{\prime}_s) + \alpha _{t-1}(l^{\prime} _{s-1}) + \alpha _{t-1}(l^{\prime} _{s-2})\right] * p(l^{\prime}_s), \ \ otherwise<br>
\end{cases}<br>
\end{equation}</p>
<h4 id="4-2-后向算法">4.2. 后向算法</h4>
<p>后向算法与前向算法的思路一模一样，在这里不再赘述。</p>
<h2 id="Inference-and-Beam-Search">Inference and Beam Search</h2>
<p><a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/36029811?group_id=972420376412762112">未待完续</a></p>
<h2 id="Reference">Reference</h2>
<ul>
<li><a target="_blank" rel="noopener" href="https://distill.pub/2017/ctc/">https://distill.pub/2017/ctc/</a></li>
<li><a target="_blank" rel="noopener" href="https://towardsdatascience.com/intuitively-understanding-connectionist-temporal-classification-3797e43a86c">https://towardsdatascience.com/intuitively-understanding-connectionist-temporal-classification-3797e43a86c</a></li>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/watch?v=UMxvZ9qHwJs">https://www.youtube.com/watch?v=UMxvZ9qHwJs</a></li>
</ul>
</div></article></div></main><footer><div class="paginator"><a href="/uncategorized/BatchNormalization%20and%20LayerNormalization/" class="prev">← BACK</a><a href="/Computer-Vision/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%9A%84mAP%E4%B8%8EIOU/" class="next">NEXT →</a></div><div class="copyright"><p>© 2020 - 2023 shayue.wt. Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">Apollo</a></p></div></footer></body><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></html>