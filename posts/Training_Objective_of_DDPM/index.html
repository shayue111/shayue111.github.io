<!DOCTYPE html><html lang="zh-Hans"><head><meta charset="utf-8"><meta name="X-UA-Compatible" content="IE=edge"><title> Training Objective of DDPM · Shayue'Log</title><meta name="description" content="Training Objective of DDPM - wangt"><meta name="viewport" content="width=device-width, initial-scale=1"><link rel="icon" href="/images/waterlemon.png"><link rel="stylesheet" href="/css/apollo.css"><link rel="search" type="application/opensearchdescription+xml" href="https://shayue111.github.io/atom.xml" title="Shayue'Log"><!-- hexo injector head_end start -->
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.12.0/dist/katex.min.css">

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/hexo-math@4.0.0/dist/style.css">
<!-- hexo injector head_end end --><meta name="generator" content="Hexo 5.2.0"><link rel="alternate" href="/atom.xml" title="Shayue'Log" type="application/atom+xml">
</head><body><header><ul class="nav nav-list"><li class="nav-list-item"><a href="/" target="_self" class="nav-list-link">POSTS</a></li><li class="nav-list-item"><a href="/archives/" target="_self" class="nav-list-link">ARCHIVE</a></li><li class="nav-list-item"><a href="/categories/" target="_self" class="nav-list-link">CATEGORY</a></li><li class="nav-list-item"><a href="/tags/" target="_self" class="nav-list-link">TAG</a></li><li class="nav-list-item"><a href="/about/" target="_self" class="nav-list-link">ABOUT</a></li></ul></header><main class="container"><script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"] ],
        displayMath: [ ['$$','$$'], ["\\[","\\]"] ],
        processEscapes: true
    }
});</script><script type="text/x-mathjax-config">MathJax.Hub.Config({
    tex2jax: {
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});</script><script async type="text/javascript" src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><div class="post"><article class="post-block"><h1 class="post-title">Training Objective of DDPM</h1><div class="post-info">May 3, 2023<a href="/tags/Diffusion-Model/" class="tag-title"># Diffusion Model</a><a href="/tags/Math-Heavy/" class="tag-title"># Math Heavy</a></div><div class="post-content"><blockquote>
<p>很多次翻看DDPM，始终不太能理解论文中提到的$\text{Variational Inference}$到底是如何在这个工作中起到作用。五一假期在家，无意间又刷到徐亦达老师早些年录制的理论视频，没想到其中也有介绍这部分的内容。老师的上课方式总是娓娓道来，把每一步都讲解得很仔细。本文记录一下个人对开头问题的思考。</p>
</blockquote>
<a id="more"></a>
<h1>Background</h1>
<p>如果需要简略地介绍一下<a target="_blank" rel="noopener" href="https://arxiv.org/abs/2006.11239">DDPM</a>这个工作，可能会用以下几句话简单地描述：<code>DDPM</code>以<code>Markov</code>的形式对数据（图片）“扩散过程”建模，使用神经网络进行训练拟合，学习数据的概率分布。</p>
<p>所以对于生成任务来说，希望从给定数据中学习到的是数据的潜在信息。比如图片生成，在给定一些图片后，模型学习到的是“正常图片长什么样子”，如：</p>
<ol>
<li>一张包含手机正面的图片会有【手机屏幕】；</li>
<li>一张包含猫咪的图片会有人们观察到的猫咪模样；</li>
<li>…</li>
</ol>
<p>对于图片中每个像素点和附近的像素点，进行“合理”布局，才能生成“符合人们认知的图片”。</p>
<p><strong>图片生成</strong>能像常见的机器学习任务如分类任务、回归任务，能基于<code>maximize likelihood</code>的形式来训练么？</p>
<p>**结论是很难，**先回顾如何做<code>maximum likelihood</code>。给定一批数据，首先需要假定数据服从的分布，接着写出似然函数，之后直接通过解析解的形式或是梯度下降的形式，求出分布。</p>
<p>问题就出在<strong>假定分布</strong>这一步，没有人知道图片客观上服从什么分布。那如果使用神经网络直接拟合可以么？这好像也不现实，拿一张<code>512*512*3</code>的图片来说，网络输出层共有约<code>75w</code>的数值。</p>
<p>对于图片生成还有另外一个问题，世界上的<strong>图片太多了</strong>，目之所及稍做处理，皆为图片。即便使用神经网络能拟合，最后生成的图片很难存在多样性。</p>
<p>那目前图片生成模型都是怎么做的，比如<code>VAE</code>或是本文即将要介绍的<code>Diffusion Model</code>，它们学习的都是数据分布$p(x)$，但直接求$p(x)$这么麻烦，需要怎么做？这其实也是$\text{Variational Inference}$的核心思想，“曲线救国”，通过引入其它分布，将原本难以优化的问题转变为可优化问题。<br>
<a name="OsljP"></a></p>
<h1>ELOB</h1>
<p>先把上述提到的所有背景先抛开，研究一下$p(x)$，看看能得到什么有意思的结论。</p>
<p>a. 基于贝叶斯定理进行变换：$p(x) = \frac{p(x, z)}{p(z\mid x)}$，$z$是另一个随机变量；</p>
<p>b. 对于两边同时取$\ln$，等式依然成立，因此有：$\ln{p(x)} = \ln{\frac{p(x, z)}{p(z \mid x)}}$；</p>
<p>c. 右边分子分母同乘以$q(z)$：<br />$\ln{p(x)} = \ln{\frac{p(x, z) * q(z)}{p(z \mid x) * q(z)}} = \ln{\left(\frac{p(x, z)}{q(z)} * \frac{q(z)}{p(z \mid x)}\right)} = \ln{\frac{p(x, z)}{q(z)}} + \ln{\frac{q(z)}{p(z \mid x)}}$</p>
<p>d. 再次，对于上式左右两边求关于$q(z)$的期望，等式依然成立：<br />$\begin{equation}<br>
\begin{align}<br>
&amp;\mathbb{E}<em>{z\sim q(z)}{[\ln{p(x)}]} = \mathbb{E}</em>{z\sim q(z)}{(\ln{\frac{p(x, z)}{q(z)}} + \ln{\frac{q(z)}{p(z \mid x)}})} \<br>
\iff &amp; \int_z q(z)\ln{p(x)}dz = \int_z q(z)\ln{\frac{p(x, z)}{q(z)}}dz + \int_z q(z)\ln{\frac{q(z)}{p(z \mid x)}}dz \<br>
\iff &amp; \ln{p(x)} = \int_z q(z)\ln{\frac{p(x, z)}{q(z)}}dz + \int_z q(z)\ln{\frac{q(z)}{p(z \mid x)}}dz<br>
\end{align}<br>
\end{equation}$</p>
<p>一系列变换后，$(1)$式是最后的推导结果，等式右边由两个项组成。第二个项$\int_z q(z)\ln{\frac{q(z)}{p(z \mid x)}}dz$，叫做<a target="_blank" rel="noopener" href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">KL散度</a>，它被用来衡量两个分布之间的“距离”，<strong>性质是值不小于0</strong>。</p>
<p>这样一来，通过$(1)$可以得到不等式$(2)$：<br />$\begin{equation}<br>
\ln{p(x)} \geq \int_z q(z)\ln{\frac{p(x, z)}{q(z)}}dz<br>
\end{equation}$</p>
<p>$(1)$式右边的第一项，同时也是$(2)$式的右边项，被学者们叫做$\text{ELBO(Evidence Lower Bound)}$。<br>
<a name="rciCk"></a></p>
<h1>Objective Function</h1>
<p>上述推导的$(2)$式可以被视作“定理”一般的存在，即对于某个分布的对数形式，总可以找到它的下界。</p>
<p>那$(2)$式可以用来做什么？在<code>Background</code>中提到，图片生成任务中的$p(x)$想要对它做<code>maximum likelihood</code>根本无法做起。目标依然是最大化$p(x)$，但有了$(2)$式，求解的目标可以转移到最大化它的下界$\text{ELBO}$。</p>
<p>这也是论文中提到的：</p>
<blockquote>
<p>This paper presents progress in diffusion probabilistic models. A diffusion probabilistic model (which we will call a “diffusion model” for brevity) is a parameterized Markov chain trained using variational inference to produce samples matching the data after finite time.</p>
</blockquote>
<p>接下来，回到论文中，看看是如何一步步推导出<code>DDPM</code>的优化目标。$(3)$式直接摘录于论文：<br />$\ln{p(x)} \geq \int_z q(z)\ln{\frac{p(x, z)}{q(z)}}dz = \mathbb{E}_{z \sim q(z)}\left[\ln{\frac{p(x,z)}{q(z)}}\right]\tag{2}$</p>
<p>$\begin{equation}<br>
\mathbb{E}\left[-\log p_\theta\left(\mathbf{x}<em>0\right)\right] \leq \mathbb{E}<em>q\left[-\log \frac{p</em>\theta\left(\mathbf{x}</em>{0: T}\right)}{q\left(\mathbf{x}_{1: T} \mid \mathbf{x}<em>0\right)}\right]=\mathbb{E}<em>q\left[-\log p\left(\mathbf{x}<em>T\right)-\sum</em>{t \geq 1} \log \frac{p</em>\theta\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}_t\right)}{q\left(\mathbf{x}<em>t \mid \mathbf{x}</em>{t-1}\right)}\right]=: L<br>
\end{equation}$<br />下面一项项地对$(3)$ 进行拆解，并且将它与$(2)$比对，能帮助更好地理解：</p>
<ol>
<li>
<p>$(3)$不等号左边的$\mathbb{E}\left[-\log p_\theta\left(\mathbf{x}<em>0\right)\right]$进一步化简就是$-\log p</em>\theta\left(\mathbf{x}<em>0\right)$。其中，$p</em>\theta\left(\mathbf{x}_0\right)$便是模型要学习的最终目标：图像的分布，$\theta$是模型的参数，$\mathbf{x}_0$是图片；</p>
</li>
<li>
<p>$(2)$式的左右两边同时加上符号，$\geq$变为$\leq$；</p>
</li>
<li>
<p>看$(3)$不等式右边部分，$\mathbb{E}<em>q\left[-\log \frac{p</em>\theta\left(\mathbf{x}<em>{0: T}\right)}{q\left(\mathbf{x}</em>{1: T} \mid \mathbf{x}_0\right)}\right]$</p>
<ol>
<li>很明显，$q(\mathbf{x}_{1:T} \mid \mathbf{x}_0)$相当于$(2)$中引入的额外分布$q(z)$。对于$z$，在生成模型中会给它一个称呼：隐变量$(\text{latent})$。实际上，在<code>diffusion models</code>里，对$\mathbf{x}_0$加噪后的$\mathbf{x}_1,\mathbf{x}_2,\ldots, \mathbf{x}_T$就可以看作隐变量，那不妨记作$z := {\mathbf{x}_1,\mathbf{x}_2,\ldots, \mathbf{x}_T}$；</li>
<li>$p_\theta\left(\mathbf{x}<em>{0: T}\right) = p</em>\theta\left(\mathbf{x}<em>{0}, \mathbf{x}</em>{1}, \ldots, \mathbf{x}_{T}\right)$，是关于$\mathbf{x}_0, z$的联合概率分布，因为选用马尔代夫链建模，那么依据马尔可夫链的性质，论文定义：</li>
</ol>
</li>
</ol>
<p>$\begin{equation}<br>
\begin{align}<br>
q\left(\mathbf{x}<em>{1: T} \mid \mathbf{x}<em>0\right)&amp;:=\prod</em>{t=1}^T q\left(\mathbf{x}<em>t \mid \mathbf{x}</em>{t-1}\right) \<br>
p</em>\theta\left(\mathbf{x}<em>{0: T}\right)&amp;:=p\left(\mathbf{x}<em>T\right) \prod</em>{t=1}^T p</em>\theta\left(\mathbf{x}_{t-1} \mid \mathbf{x}_t\right)<br>
\end{align}<br>
\end{equation}$</p>
<ol start="3">
<li>将$(4)$带入$(3)$不等式右边的第一项，得到$L$：</li>
</ol>
<p>$\begin{align}<br>
&amp;\mathbb{E}<em>q\left[-\log \frac{p</em>\theta\left(\mathbf{x}<em>{0: T}\right)}{q\left(\mathbf{x}</em>{1: T} \mid \mathbf{x}<em>0\right)}\right] \<br>
=&amp;\mathbb{E}<em>q\left[-\log \frac{p\left(\mathbf{x}<em>T\right) \prod</em>{t=1}^T p</em>\theta\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}<em>t\right)}{\prod</em>{t=1}^T q\left(\mathbf{x}<em>t \mid \mathbf{x}</em>{t-1}\right)}\right] \<br>
=&amp;\mathbb{E}<em>q\left[-\log p\left(\mathbf{x}<em>T\right)-\sum</em>{t \geq 1} \log \frac{p</em>\theta\left(\mathbf{x}_{t-1} \mid \mathbf{x}<em>t\right)}{q\left(\mathbf{x}<em>t \mid \mathbf{x}</em>{t-1}\right)}\right] := L<br>
\end{align}$<br />到目前为止，经过了很多轮的变换以及数学公式，先捋一遍，再往下。<br />$L$<strong>是一个替代的优化目标，</strong>$\argmin{(L)} \iff \argmin{(-\ln{p}</em>{\theta}(\mathbf{x}<em>0))} \iff \argmax{(\ln{p}</em>{\theta}(\mathbf{x}_0))}$</p>
<p>接下来，论文中对$L$进行了重写，以下步骤直接摘录自论文$\text{Appendix A}$</p>
<p>$\begin{equation}\begin{aligned} L &amp; =\mathbb{E}<em>q\left[-\log \frac{p</em>\theta\left(\mathbf{x}<em>{0: T}\right)}{q\left(\mathbf{x}</em>{1: T} \mid \mathbf{x}<em>0\right)}\right] \ &amp; =\mathbb{E}<em>q\left[-\log p\left(\mathbf{x}<em>T\right)-\sum</em>{t \geq 1} \log \frac{p</em>\theta\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}<em>t\right)}{q\left(\mathbf{x}<em>t \mid \mathbf{x}</em>{t-1}\right)}\right] \ &amp; =\mathbb{E}<em>q\left[-\log p\left(\mathbf{x}<em>T\right)-\sum</em>{t&gt;1} \log \frac{p</em>\theta\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}<em>t\right)}{q\left(\mathbf{x}<em>t \mid \mathbf{x}</em>{t-1}\right)}-\log \frac{p</em>\theta\left(\mathbf{x}_0 \mid \mathbf{x}_1\right)}{q\left(\mathbf{x}_1 \mid \mathbf{x}<em>0\right)}\right] \<br>
&amp;=\mathbb{E}<em>q\left[-\log p\left(\mathbf{x}<em>T\right)-\sum</em>{t&gt;1} \log \left[\frac{p</em>\theta\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}<em>t\right)}{q\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}_t, \mathbf{x}<em>0\right)} \cdot \frac{q\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}_0\right)}{q\left(\mathbf{x}_t \mid \mathbf{x}<em>0\right)}\right]-\log \frac{p</em>\theta\left(\mathbf{x}_0 \mid \mathbf{x}_1\right)}{q\left(\mathbf{x}_1 \mid \mathbf{x}_0\right)}\right]<br>
\end{aligned}<br>
\end{equation}$</p>
<p>倒数两步的变换发生在第二项，具体依据为：<br />$\begin{align}<br>
q\left(\mathbf{x}<em>t \mid \mathbf{x}</em>{t-1}\right)<br>
=&amp; \frac{q\left(\mathbf{x}<em>t, \mathbf{x}</em>{t-1}\right)}{q\left(\mathbf{x}<em>{t-1}\right)} \<br>
=&amp; \frac{q\left(\mathbf{x}<em>t, \mathbf{x}</em>{t-1} \mid \mathbf{x}</em>{0}\right) *q(\mathbf{x}<em>{0})}{q\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}<em>{0}\right) * q(\mathbf{x}</em>{0})} \<br>
=&amp; \frac{q\left(\mathbf{x}<em>t, \mathbf{x}</em>{t-1} \mid \mathbf{x}<em>{0}\right) }{q\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}<em>0\right)}<br>
\end{align}<br>
\quad \Rightarrow \quad<br>
\begin{align}<br>
&amp;\sum</em>{t&gt;1} \log \frac{p_\theta\left(\mathbf{x}<em>{t-1} \mid \mathbf{x}<em>t\right)}{q\left(\mathbf{x}<em>t \mid \mathbf{x}</em>{t-1}\right)} \<br>
=&amp; \sum</em>{t&gt;1} \log \frac{p</em>\theta\left(\mathbf{x}<em>{t-1} \mid \mathbf{x}<em>t\right)}{q\left(\mathbf{x}<em>t, \mathbf{x}</em>{t-1} \mid \mathbf{x}</em>{0}\right) } \cdot {q\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}<em>0\right)} \<br>
=&amp; \sum</em>{t&gt;1} \log \frac{p_\theta\left(\mathbf{x}_{t-1} \mid \mathbf{x}<em>t\right)}{q\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}_t, \mathbf{x}<em>0\right)} \cdot \frac{q\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}_0\right)}{q\left(\mathbf{x}_t \mid \mathbf{x}_0\right)}<br>
\end{align}$</p>
<p>接着对$(5)$进行改写得到最终形式$(6)$：<br />$\begin{equation}<br>
\begin{align}<br>
L &amp;=\mathbb{E}_q\left[-\log \frac{p\left(\mathbf{x}<em>T\right)}{q\left(\mathbf{x}<em>T \mid \mathbf{x}<em>0\right)}-\sum</em>{t&gt;1} \log \frac{p</em>\theta\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}<em>t\right)}{q\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}<em>t, \mathbf{x}<em>0\right)}-\log p</em>\theta\left(\mathbf{x}<em>0 \mid \mathbf{x}<em>1\right)\right] \<br>
&amp;=\mathbb{E}<em>q[\underbrace{D</em>{\mathrm{KL}}\left(q\left(\mathbf{x}<em>T \mid \mathbf{x}<em>0\right) | p\left(\mathbf{x}<em>T\right)\right)}</em>{L_T}+\sum</em>{t&gt;1} \underbrace{D</em>{\mathrm{KL}}\left(q\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}<em>t, \mathbf{x}<em>0\right) | p</em>\theta\left(\mathbf{x}</em>{t-1} \mid \mathbf{x}<em>t\right)\right)}</em>{L</em>{t-1}} \underbrace{-\log p</em>\theta\left(\mathbf{x}_0 \mid \mathbf{x}<em>1\right)}</em>{L_0}]<br>
\end{align}<br>
\end{equation}$<br>
<a name="y8x7s"></a></p>
<h1>Summary</h1>
<p>太好了，对于$(6)$来说，它最起码是个可以优化的目标函数了，因为论文中定义马尔可夫链相邻状态的转变是服从高斯分布的。当然在论文中，$(6)$还会进一步被改写，最后得到更加精简的$\text{loss function}$的形式。本文主要还是基于<code>DDPM</code>，对$\text{variational inference}$的一些学习。<br>
<a name="SWBBd"></a></p>
<h1>Reference</h1>
<ul>
<li><a target="_blank" rel="noopener" href="https://www.youtube.com/playlist?list=PLyAft-JyjIYoN_6X932U_-ZlHKdInFrUV">Variational Inference Basic, Xu, R.Y.D</a></li>
<li><a target="_blank" rel="noopener" href="https://arxiv.org/abs/2006.11239">Denoising Diffusion Probabilistic Models</a></li>
</ul>
</div></article></div></main><footer><div class="paginator"><a href="/posts/LoRA_Explained/" class="next">NEXT →</a></div><div class="copyright"><p>© 2020 - 2023 shayue.wt. Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> and <a href="https://github.com/pinggod/hexo-theme-apollo" target="_blank">Apollo</a></p></div></footer></body><script async src="//cdn.bootcss.com/mathjax/2.7.0/MathJax.js?config=TeX-MML-AM_CHTML" integrity="sha384-crwIf/BuaWM9rM65iM+dWFldgQ1Un8jWZMuh3puxb8TOY9+linwLoI7ZHZT+aekW" crossorigin="anonymous"></script></html>