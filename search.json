[{"title":"理解R-CNN","url":"/posts/%E7%90%86%E8%A7%A3R-CNN/","content":"<blockquote>\n<p>最近需要使用目标检测对表格内容提取，故决定将该领域的学习以博客的形式记录下来。这是系列文章的第一部分，主要介绍R-CNN的模型结构，特别是弄懂论文中如何训练R-CNN。本文参考了几篇优秀的文章，如果感兴趣尽可以跳到最后阅读原文。</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"1-简介\">1. 简介</h2>\n<p>本文将要介绍的是2014年来自UC Berkeley的一篇论文<a href=\"https://arxiv.org/pdf/1311.2524.pdf\">《Rich feature hierarchies for accurate object detection and semantic segmentation》</a>。论文摒弃传统手工提取特征的做法，转而使用CNN架构提取图像特征。虽然现在看来，R-CNN的架构有一定的不足，但是引入CNN的做法使得目标检测领域有了新的研究方向。</p>\n<p>下面我将尽可能简略地介绍R-CNN的思想以及其训练过程。在介绍开始前，我会假设您对DNN、CNN以及分类任务和目标检测任务已经有一定的了解。</p>\n<h2 id=\"2-模型介绍\">2. 模型介绍</h2>\n<p>R-CNN的运作方式如下：</p>\n<ol>\n<li>输入一张完整的图片；</li>\n<li>从中提取大约2000个region proposals;</li>\n<li>将这些提取出来的region proposals送入CNN提取特征；</li>\n<li>将CNN转化得到的特征送入线性分类器SVM中进行分类。</li>\n</ol>\n<p>下图是论文中给出的示意图：</p>\n<p><img src=\"/images/R-CNN/rcnn.png\" alt=\"R-CNN Overview\"></p>\n<center style=\"font-size:14px;color:#C0C0C0\">R-CNN Overview, from https://arxiv.org/pdf/1311.2524.pdf</center>\n<p>R-CNN最值得称赞的地方无疑是采用region proposals加上CNN进一步提取特征。</p>\n<h4 id=\"2-1-提取Region-Proposals\">2.1. 提取Region Proposals</h4>\n<p>我们需要一些算法去提取Region。算法的输入是一张图片，输出是若干个可能包含目标物体的区域，比如可以使&lt;$c_x, c_y, H, W$&gt;表示一个提取出的区域，前两个变量是Anchor Box的位置坐标，后两个变量是其高度与宽度。</p>\n<p>初步得到的候选区域非常的<code>noisy</code>，它们中可能确实包含需要被检测的<code>object</code>，可能也没有。同时，输出的&lt;$c_x, c_y, H, W$&gt;也不一定准确，如下图是一张图片中提取出的若干Region Proposals，其中绿色框可以被认为是我们期待输出的Anchor Box，而蓝色框则是有缺陷的。</p>\n<p><img src=\"https://www.learnopencv.com/wp-content/uploads/2017/10/object-recognition-false-positives-true-positives.jpg\" alt=\"Region Proposals示意\"></p>\n<center style=\"font-size:14px;color:#C0C0C0\">Region Proposals Example, from https://www.learnopencv.com/selective-search-for-object-detection-cpp-python/</center>\n<p>Region proposal algorithms算法基于颜色、纹理等对一张图片进行切割，使得一些近似的区域连接在一起产生Region。Selective Search是其中的一种，也是被应用在论文中的算法。更具体的内容，本文不再阐述，有兴趣的读者可以访问<a href=\"https://www.learnopencv.com/selective-search-for-object-detection-cpp-python/\">文章</a>，有着非常详尽的介绍，并且给出了相应的实现代码。</p>\n<h4 id=\"2-2-CNN\">2.2. CNN</h4>\n<p>在得到Region proposals后，将每一个区域送到CNN架构中，得到该区域的特征向量，在论文中使用的CNN是<code>AlexNet</code>。</p>\n<p><img src=\"https://www.learnopencv.com/wp-content/uploads/2018/05/AlexNet-1.png\" alt=\"AlexNet Architecture\"></p>\n<center style=\"font-size:14px;color:#C0C0C0\">AlexNet Architecture, from https://www.learnopencv.com/understanding-alexnet/</center>\n<p><strong>第一个问题来了</strong>，这部分CNN需要怎么样被训练？因为模型后接的是若干个SVM分类器，显然两者无法一起训练。</p>\n<p>论文中的做法是对CNN部分进行<strong>预训练</strong>，具体训练这部分的参数将在之后介绍。在AlexNet的模型确定之后，将其最后一层去掉，也就是说，通过CNN后，之前的Region proposals被转化至4096维的向量。</p>\n<p><strong>另外一个问题是</strong>，AlexNet的输入是固定的，即(227, 227, 3)，而之前提取出的Region proposals形状不一，如何输入AlexNet？这就需要对每个Region进行resize的操作。</p>\n<h4 id=\"2-3-SVM\">2.3. SVM</h4>\n<p>在获得特征向量后，下一步是将其送入若干个SVM分类器中。比如，目标检测的对象有10类，那么总共要送入10个SVM分类器。</p>\n<h4 id=\"2-4-修正Anchor-Box\">2.4. 修正Anchor Box</h4>\n<p>到上一步为止，R-CNN的预测流程已经走完了一大半。最后还有一个环节就是确定目标所在的位置，即确定&lt;$c_x, c_y, H, W$&gt;。</p>\n<p>之前在提取候选区域的时候，已经有一个初步的&lt;$c_x, c_y, H, W$&gt;$_{prior}$，接下来便是对已经确实是目标的region进行修正。关于修正的算法，本质上利用一个回归器进行拟合。</p>\n<p>这样，我们便走完了R-CNN的全部流程。</p>\n<h2 id=\"3-R-CNN的训练\">3. R-CNN的训练</h2>\n<p>在这一小节，我将主要介绍如R-CNN的训练过程。R-CNN的一个重大缺陷就在于它不是端到端的，无法把所有的组件合并到一个pipeline一起训练参数。论文中的解决办法是分开训练，下面具体展开介绍。</p>\n<p><strong>CNN部分</strong>，论文使用预训练方式确定网络参数。首先，使用选定的网络架构（本例是AlexNet）在数据集<a href=\"http://image-net.org/challenges/LSVRC/2012/\">ILSVRC 2012 classification dataset</a>进行训练。该数据集中包含1000个不同类别的图片，彼时的任务是多分类。</p>\n<p>在上个任务训练结束后，将训练好的网络用于另一个任务的训练，即使用<a href=\"http://host.robots.ox.ac.uk/pascal/VOC/\">PASCAL VOC dataset</a>或<a href=\"http://image-net.org/challenges/LSVRC/2013/\">ILSVRC 2013 detection dataset</a>进行fine-tuning。上一个任务是涉及1000个类别的多分类，在这个任务中，将之前CNN的最后一层去掉，加上新的一层，对<code>N+1</code>种类别分类，此处的<code>N</code>是数据集中的类别个数。</p>\n<p>同时，网络的输入也有所变化。在pre-training阶段的输入是整张图片，在fine-tuning阶段，输入则是<code>warped region proposals</code>，即筛选出的2000个左右的候选区域。这就需要重新构建用于训练的数据集，将候选区域与ground-truth bounding box计算得到的<code>IOU &gt; 0.5</code>的视为正例，反之视为负例（即预测出来为背景）。还有一些训练的参数设置，这里不过多阐述，感兴趣的可以查看论文。</p>\n<p>最后，SVM部分考虑使用简单的二分类。比如检测region proposal是否含有车辆，有车的被视为正例，无车的被视为负例。问题主要在于，如果判定region proposal是否包含正例，论文以<code>IOU=0.3</code>为界限，这是通过验证集得出的值。</p>\n<p>分类部分的训练大致如上所述，还有一个回归器需要训练，用于对Anchor Box的修正，论文使用的修正模型是Ridge Regression。训练得到参数后，将&lt;$c_x, c_y, H, W$&gt;$_{prior}$以一定方式转化到&lt;$c_x, c_y, H, W$&gt;。</p>\n<h2 id=\"4-总结\">4. 总结</h2>\n<p>本文主要对R-CNN进行了简单的介绍，包括其预测流程以及训练流程。对于其中一些细节并没有过多的深入，因为本人认为R-CNN在2020年看来确实有些“老”，主要的缺陷集中在训练和预测速度慢，无法端到端训练等。预测时首先要提取多个region proposals，接下来对于每一个region proposal转化得到的特征向量，在分类阶段还需要送入若干个二分类SVM，整体的效率大打折扣。</p>\n<p>但是其中的一些训练思想是很值得借鉴的，先使用pre-traing，再使用fine-tuing已经是当前网络训练的基本操作。同时，整篇论文逻辑清晰，简单易懂，是很好的文章。</p>\n<h1>Reference</h1>\n<ul>\n<li><a href=\"https://arxiv.org/pdf/1311.2524.pdf\">https://arxiv.org/pdf/1311.2524.pdf</a> ，R-CNN论文</li>\n<li><a href=\"https://www.learnopencv.com/selective-search-for-object-detection-cpp-python/\">https://www.learnopencv.com/selective-search-for-object-detection-cpp-python/</a> ，介绍Selective Search</li>\n<li><a href=\"https://medium.com/@selfouly/r-cnn-3a9beddfd55a\">https://medium.com/@selfouly/r-cnn-3a9beddfd55a</a> ，介绍R-CNN</li>\n<li><a href=\"https://www.mihaileric.com/posts/object-detection-with-rcnn/\">https://www.mihaileric.com/posts/object-detection-with-rcnn/</a> ，介绍R-CNN</li>\n<li><a href=\"https://www.jianshu.com/p/9bcbf6d98238\">https://www.jianshu.com/p/9bcbf6d98238</a> ，介绍R-CNN，中文</li>\n</ul>\n","categories":["Computer Vision"],"tags":["Object Detection","R-CNN Family"]},{"title":"目标检测中的mAP与IOU","url":"/posts/%E7%9B%AE%E6%A0%87%E6%A3%80%E6%B5%8B%E4%B8%AD%E7%9A%84mAP%E4%B8%8EIOU/","content":"<blockquote>\n<p>本文将介绍目标检测任务（Object Detection）中的一般评价指标(Metric) - mAP（mean average Precison）以及IOU（Intersection over Union）。</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"Precision-Recall-Curve\">Precision Recall Curve</h2>\n<p>在多分类任务中，模型在对某个样本预测后会得到一个概率，即属于$c_i$类的概率为$p_i$，通常会用PR曲线(Precision Recall Curve)判定模型的性能。</p>\n<p>假设现在需要画出针对类别$c_i$的PR曲线，具体做法是：</p>\n<ol>\n<li>设置多个阈值(threshold)，如果类别$c_i$对应的概率为$p_i$，如果大于阈值，认为是True Positive，反之属于False Positive；</li>\n<li>step1中设置出的多个阈值将产生多组(True Positive, False Positive)。针对每一组计算<code>precision</code>与<code>recall</code>两个指标；</li>\n<li>使用step2中得到的多组(precision, recall)，以recall为横轴，precision为纵轴，画出一条曲线。</li>\n</ol>\n<p>目标检测本质上包含多分类任务，并且之后mAP的计算与上述得到PR曲线的过程类似。</p>\n<h2 id=\"IOU\">IOU</h2>\n<p>mAP的计算需要IOU的参与，因此这一部分介绍IOU的计算方式。目标检测模型在预测阶段会为图片或视频中检测出的物体（object）标记Bounding Box，同时还有概率值（confidence）。</p>\n<p>IOU的计算需要Bounding Box与Ground Truth label参与，前者是模型预测的值，后者被认为是图片中属于物体的真实范围。如下图所示，蓝色代表Bounding Box，绿色代表Ground Truth Box。</p>\n<p><img src=\"https://www.learnopencv.com/wp-content/uploads/2017/10/object-recognition-false-positives-true-positives.jpg\" alt=\"Region Proposals示意\"></p>\n<center style=\"font-size:14px;color:#C0C0C0\">Region Proposals Example, from https://www.learnopencv.com/selective-search-for-object-detection-cpp-python/</center>\n<p>IOU用于描述两个BBox间的交集程度，如下图所示，一个BBox和Ground Truth Box存在相交（绿色部分）。<br>\n<img src=\"/images/ObjectDetection/IOU.png\" alt=\"两个BBox示意\"></p>\n<center style=\"font-size:14px;color:#C0C0C0\">两个BBox示意</center>\n<p>此处IOU的计算方式如下：<br>\n$$<br>\nIOU = \\frac{Area(绿色，overlap)}{Area(蓝+绿+红，union)}<br>\n$$<br>\n由于BBox会给定4个值确定位置，所以计算面积还是很容易的。</p>\n<h2 id=\"mAP\">mAP</h2>\n<p>本部分以单张图片中单个类别所有预测出的BBox与Ground Truth Box为例，介绍mAP的计算流程。</p>\n<ol>\n<li>\n<p>选取一个阈值比如0.5，使用它对识别出来的BBox进行判断。如果该BBox的<code>IOU &gt; threshold</code>，那么认为这个BBox是<code>TP</code>，否则，认为它是<code>FP</code>；</p>\n</li>\n<li>\n<p>按照confidence降序排序，得到一个表格；</p>\n</li>\n<li>\n<p>自顶向下，通过累加计算<code>precision</code>和<code>recall</code>，并获得多组数据；</p>\n</li>\n<li>\n<p>使用step3获得的数据画出PR-curve，注意最开始应该是从(0, 1)开始的，它与坐标轴围成的面积，即是需要计算的AP。</p>\n</li>\n</ol>\n<h2 id=\"个人疑惑\">个人疑惑</h2>\n<p>分类任务中的PR曲线是由<code>多组阈值</code>计算出多组precision和recall值画出的，但是mAP中的PR-curve是通过<code>一个阈值</code>计算出多组precision和recall值画出的。不知道是我哪里理解错了，还是在mAP中就是如此规定。</p>\n<h2 id=\"Reference\">Reference</h2>\n<ul>\n<li>\n<p><a href=\"https://www.youtube.com/watch?v=FppOzcDvaDI&amp;list=PLhhyoLH6Ijfw0TpCTVTNk42NN08H6UvNq&amp;index=4\">https://www.youtube.com/watch?v=FppOzcDvaDI&amp;list=PLhhyoLH6Ijfw0TpCTVTNk42NN08H6UvNq&amp;index=4</a> ，很有才的Youtuber，英语发音也很好，发布的视频都是从0到1去实现，非常适合希望深度了解的同学</p>\n</li>\n<li>\n<p><a href=\"https://github.com/rafaelpadilla/Object-Detection-Metrics\">https://github.com/rafaelpadilla/Object-Detection-Metrics</a> ，文字版计算过程</p>\n</li>\n</ul>\n","categories":["Computer Vision"],"tags":["Object Detection","Metric"]},{"title":"Connectionist Temporal Classification","url":"/posts/Connectionist%20Temporal%20Classification/","content":"<blockquote>\n<p>由于需要进行图片文本识别相关的工作，最近接触到了CTC Loss，打算将这几天的学习进行归纳总结。如果有接触过<code>HMM</code>的相关内容，看到<code>CTC</code>可能会觉得很亲切。</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"1-前言\">1. 前言</h2>\n<p>如果想要识别图片中的文字，神经网络是一个不错的选择，它们在大多数情况下表现良好。一般来说，用于文本识别工作的神经网络会用到<code>convolutional layers</code>和<code>recurrent layers</code>，前者常被用于提取图片中的特征并送入后者。后者的输出是一个矩阵，存放着每个时间步中属于某个字符的概率。基于CRNN架构的文字识别如下图所示，</p>\n<p><img src=\"/images/ObjectDetection/CTC.png\" alt=\"CRNN Overview\"></p>\n<center style=\"font-size:14px;color:#C0C0C0\">Figure1, CRNN Overview</center>\n<p>要训练这样的网络，可以设想一下最通俗的做法，那就是字符级别的分类识别。比如对于上图来说，同时需要标注图片中每个字符的位置，比如图片中<code>A</code>所在的位置，然后这个部分对应的字符是<code>A</code>，依次类推，对这张图片里的其他字符还需要做同样标注行为。对于图片，这样标注仅仅只是耗时，但是有些任务比如语音识别，甚至无法标注字符出现的位置。</p>\n<p>为了解决上述难题，<a href=\"https://www.cs.toronto.edu/~graves/icml_2006.pdf\">CTC</a>被提出了，它是一种能让RNN直接利用图片数据或语音数据与文本数据进行端到端训练的方法。</p>\n<h2 id=\"2-对齐\">2. 对齐</h2>\n<p>不标注字符的具体位置，对于像图片数据转文字或者语音数据转文字的任务，会存在一个问题，那就是如何将输入与输出<code>对齐</code>。</p>\n<p>拿图片来说，输入图片经过CNN后转化得到特征向量，将这些特征组成序列输入RNN。为了方便，RNN的序列步长<code>T</code>是固定的，相应的，RNN的输出也是<code>T</code>。但是，我们不能保证数据集<code>&lt;X, Y&gt;</code>中的文字长度都是<code>T</code>，RNN的输入与标签   <code>y</code>可能无法对齐。比如在图片<code>Figure1</code>中，设<code>T = 10</code>，而目标单词<code>Available</code>的长度只有9，此时就无法对齐。</p>\n<p>为了解决对齐问题，为<code>Figure1</code>增加<code>CTC Layer</code>，加在RNN输出之后。</p>\n<p><img src=\"/images/ObjectDetection/CTC_decoder.png\" alt=\"CRNN Overview\"></p>\n<center style=\"font-size:14px;color:#C0C0C0\">Figure2, CRNN with decoder</center>\n<p>如<code>Figure2</code>所示，设RNN输出的步长固定为10。当$y_i$的长度不足10时，允许RNN能在相邻位置上预测出相同的字符。在<code>CTC layer</code>中解码时，将相邻相同的字符合并即可。</p>\n<p>但是，又来了一个问题，如果$y_i == hello$，即标签中相邻位置本就存在相同字符，上述的解码策略就行不通了。为此，再引入一个特殊字符$\\epsilon$，称作<code>blank token</code>，在解码的时候去掉。如果RNN序列长度还是10，那么比如RNN输出路径为$h e l \\epsilon l \\epsilon o o o o$，是能被解码到<code>hello</code>的。</p>\n<p>总结来说，为了能够解决<strong>对齐问题</strong>，我们在<code>RNN layer</code>后加了<code>CTC layer</code>，并且为<code>RNN</code>的字符分类增加新的一类$\\epsilon$。根据相应的解码规则，期待<code>RNN</code>的输出在经过<code>CTC</code>的转化后能得到正确路径。更加具体的解码细节，会放在<code>第4部分概率计算</code>中介绍。</p>\n<h2 id=\"3-目标函数\">3. 目标函数</h2>\n<p>终于来到本文的重点，这一部分将介绍<code>CTC Loss</code>。</p>\n<p>到现在为止，我们知道RNN要处理的是多对多的多分类问题，它需要将输入的特征序列转化为序列矩阵。矩阵的每一行是字符所对应的类别，矩阵的每一列是所处的时间步。</p>\n<h4 id=\"3-1-概率\">3.1. 概率</h4>\n<p>为了更加形象，下面以具体的任务进行举例。假设待预测的图片只包括<code>我爱学习</code>4个字，<code>RNN</code>在每个时间步需要预测的字符也仅有5类$\\{我，爱，学，习，\\epsilon\\}$，RNN的序列步长固定为5。那么RNN的一次输出可能产生如下矩阵：</p>\n<table>\n<thead>\n<tr>\n<th style=\"text-align:center\"></th>\n<th style=\"text-align:center\">$step_1$</th>\n<th style=\"text-align:center\">$step_2$</th>\n<th style=\"text-align:center\">$step_3$</th>\n<th style=\"text-align:center\">$step_4$</th>\n<th style=\"text-align:center\">$step_5$</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\"><strong>我</strong></td>\n<td style=\"text-align:center\">0.469</td>\n<td style=\"text-align:center\">0.202</td>\n<td style=\"text-align:center\">0.244</td>\n<td style=\"text-align:center\">0.011</td>\n<td style=\"text-align:center\">0.154</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>爱</strong></td>\n<td style=\"text-align:center\">0.043</td>\n<td style=\"text-align:center\">0.217</td>\n<td style=\"text-align:center\">0.211</td>\n<td style=\"text-align:center\">0.314</td>\n<td style=\"text-align:center\">0.185</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>学</strong></td>\n<td style=\"text-align:center\">0.249</td>\n<td style=\"text-align:center\">0.179</td>\n<td style=\"text-align:center\">0.207</td>\n<td style=\"text-align:center\">0.152</td>\n<td style=\"text-align:center\">0.204</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>习</strong></td>\n<td style=\"text-align:center\">0.144</td>\n<td style=\"text-align:center\">0.13</td>\n<td style=\"text-align:center\">0.137</td>\n<td style=\"text-align:center\">0.296</td>\n<td style=\"text-align:center\">0.227</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><strong>$\\epsilon$</strong></td>\n<td style=\"text-align:center\">0.096</td>\n<td style=\"text-align:center\">0.272</td>\n<td style=\"text-align:center\">0.2</td>\n<td style=\"text-align:center\">0.227</td>\n<td style=\"text-align:center\">0.231</td>\n</tr>\n</tbody>\n</table>\n<p>每一个时间步，所有字符出现的概率和为1。下面，可以通过这个矩阵计算出解码层最后输出<code>我爱学习</code>的概率。首选需要列出所有可能解码出<code>我爱学习</code>的路径，但是值得一提的是，实际的解码过程中并不会通过这种穷举方法得到需要的概率，因为计算量非常的大。</p>\n<p><strong>路径：</strong></p>\n<ol>\n<li>$\\epsilon$ -&gt; 我 -&gt; 爱 -&gt; 学 -&gt; 习</li>\n<li>我 -&gt; $\\epsilon$ -&gt; 爱 -&gt; 学 -&gt; 习</li>\n<li>我 -&gt; 爱 -&gt; $\\epsilon$ -&gt; 学 -&gt; 习</li>\n<li>我 -&gt; 爱 -&gt; 学 -&gt; $\\epsilon$ -&gt; 习</li>\n<li>我 -&gt; 爱 -&gt; 学 -&gt; 习 -&gt; $\\epsilon$</li>\n<li>我 -&gt; 我 -&gt; 爱 -&gt; 学 -&gt; 习</li>\n<li>我 -&gt; 爱 -&gt; 爱 -&gt; 学 -&gt; 习</li>\n<li>我 -&gt; 爱 -&gt; 学 -&gt; 学 -&gt; 习</li>\n<li>我 -&gt; 爱 -&gt; 学 -&gt; 习 -&gt; 习</li>\n</ol>\n<p>上面列出了所有能得到正确解码序列的路径，共有9条。路径数量会受到RNN序列长度、标签文字长度以及标签文字中重复字符的个数的影响，而且是指数级别的增长。</p>\n<p>接下来，需要分别计算上述路径的概率，之后再求和，即可得到模型输出<code>我爱学习</code>的概率。</p>\n<p>\\begin{equation}<br>\n\\tag{1}<br>\np(我爱学习|x) = \\sum_{j=1}^{m=9} p(path^j|x) = \\sum_{j=1}^{9} (\\prod_{t=1}^5 p(z_t^j|x))<br>\n\\end{equation}</p>\n<h4 id=\"3-2-最大似然估计\">3.2. 最大似然估计</h4>\n<blockquote>\n<p>参数的概率估计问题总是绕不过<code>MLE</code>。</p>\n</blockquote>\n<p>前面已经以计算$p(我爱学习|x)$作为概率计算的举例。假定现在有一组数据集，包括$N$组图片与文字$\\left&lt;x_n, y_n\\right&gt;$的对应关系，记作$\\left&lt;X, Y\\right&gt;$。同样的，分别计算出这些样本产出的概率（再次强调，不会穷举计算，具体算法文章之后会介绍），得到若干组概率$p(y_n|x_n)$。</p>\n<p>根据极大似然的思想，<strong>好的模型，或者说好模型的参数</strong>会令似然函数最大，希望根据下式得到模型的参数（为了书写简便$\\theta$有时省略），有：</p>\n<p>\\begin{equation}<br>\n\\tag{2}<br>\n\\theta^* = \\underset{\\theta}{\\mathrm{argmin}} \\prod_{n=1}^N  p(y_n|x_n, \\theta)<br>\n\\end{equation}</p>\n<p>到这里，我们就得到了<code>CTC Loss</code>的目标函数(Objective function)，如下所示：</p>\n<p>\\begin{equation*}<br>\n\\tag{3}<br>\n\\label{a}<br>\n\\max \\prod_{n=1}^N  p(y_n|x_n) \\iff \\max \\sum_{n=1}^N \\log p(y_n|x_n) \\<br>\n\\iff \\min -\\sum_{n=1}^N  \\log p(y_n|x_n)<br>\n\\end{equation*}</p>\n<p>如$\\eqref{a}$式所示，目标是<code>最小化negative log-likelihood</code>。</p>\n<h2 id=\"4-概率计算\">4. 概率计算</h2>\n<p>在<code>3.1</code>中我们用穷举的方法列出了所有能得到文本<code>我爱学习</code>的可能路径，下面将介绍<code>CTC</code>的另一个核心部分，即如何优化概率计算算法。</p>\n<p>CTC中用到概率计算算法与HMM的前向-后向算法很像，论文中称作<code>CTC Forward-Backward Algorithm</code>，下面以该称呼指代。前向-后向算法关注的点在于如何利用相邻时间步状态的关系简化计算量。</p>\n<p>论文给出前向概率的定义如下：</p>\n<p>\\begin{equation}<br>\n\\tag{4}\\label{b}<br>\np(y_1, y_2, \\cdots, y_s|x) = \\alpha_{t}(s) \\stackrel{def}{=} \\sum_{\\pi \\in N^{T}: \\atop \\mathcal{B}\\left(\\pi_{1:t}\\right)=label_{1:s}} {} \\prod_{t^{\\prime}=1}^{t} y_{\\pi_{t^{\\prime}}}^{t^{\\prime}}<br>\n\\end{equation}</p>\n<p>其中：</p>\n<ul>\n<li>$\\pi$是单条可能的路径，$N^{T}$是所有的路径，$T$是RNN的输入(输出)步长；</li>\n<li>$\\mathcal{B}$是解码的规则，就像前面说的那样，<code>删除重复字符</code>与<code>去除blank token</code>；</li>\n<li>$t$代表路径中的第几个时间步，$s$代表标签的第几个字符。</li>\n</ul>\n<p>总体来说，$\\eqref{b}$看起来非常抽象，下面结合实际的标注文本：$我爱学习$</p>\n<p>假定将RNN的输出步长$T$固定为10。现在需要计算第2个字符<code>爱</code>在时间步为5时的前向概率，那么可以写作$\\alpha_{5}(\\text{爱})$。为了更加清楚，在定义上加上字符的位置信息，写作$\\alpha_{5}(label_2=\\text{爱})$</p>\n<p>此时，$label_{1:s}$就是$label_{1:2}$：$我爱$。我们需要找到所有的$\\pi$，使得 $\\mathcal{B}(\\pi_{1:5}) == 我爱$。</p>\n<p>比如，其中符合要求的路径$\\pi$可以是：</p>\n<ul>\n<li>$\\epsilon \\rightarrow \\epsilon \\rightarrow 我 \\rightarrow \\epsilon \\rightarrow 爱 \\rightarrow \\cdots$</li>\n<li>$\\epsilon \\rightarrow 我 \\rightarrow 我 \\rightarrow \\epsilon \\rightarrow 爱 \\rightarrow \\cdots$</li>\n<li>$\\epsilon \\rightarrow 我 \\rightarrow \\epsilon \\rightarrow 爱 \\rightarrow 爱 \\rightarrow \\cdots$</li>\n<li>$\\cdots$</li>\n</ul>\n<p>如上所示，虽然规定路径的长度为10，但由于需要的时间步$t$只有5，仅考虑前5个字符组合之后，符合解码需求的路径。</p>\n<h4 id=\"4-1-前向算法\">4.1. 前向算法</h4>\n<p>下面先用一张图来介绍前向过程中「字符的流动」。</p>\n<p><img src=\"/images/ObjectDetection/CTC_forward.png\" alt=\"CTC Forward\"></p>\n<center style=\"font-size:14px;color:#C0C0C0\">Figure3, CTC Forward</center>\n<p>需要注意的这张图并不是RNN的输出矩阵，实际的输出矩阵还是只有5行，「我，爱，学，习，$\\epsilon$」。这里只是为了让前向过程的状态转变更好理解，所以做了添加$\\epsilon$的操作。</p>\n<p>$\\epsilon$在图中用<code>-</code>表示。我们先是将$\\epsilon$分别插入文本的头尾以及内部，然后从左上到右下，将所有可能得到$我爱$的路径画了出来。</p>\n<p>为了契合上面的变化，对于文本也做相应的变化：$$label「我爱学习」\\rightarrow label^{\\prime} 「\\epsilon我\\epsilon爱\\epsilon学\\epsilon习\\epsilon」$$</p>\n<p>要获取$\\alpha_{5}(label_2=\\text{爱})$，可以利用公式(5)：</p>\n<p>\\begin{equation}<br>\n\\tag{5}<br>\n\\alpha_{5}(label_2=\\text{爱}) = \\alpha_{5}(label^{\\prime}_ 4=\\text{爱}) + \\alpha_{5}(label^{\\prime}_5=\\epsilon)<br>\n\\end{equation}</p>\n<p>而，<br>\n\\begin{equation}<br>\n\\begin{aligned}<br>\n\\alpha_{5}(label^{\\prime}_ 4=\\text{爱}) &amp;= \\left(\\alpha_{4}(label^{\\prime}_ 4=\\text{爱}) + \\alpha_{4}(label^{\\prime}_ 3=\\epsilon) + \\alpha_{4}(label^{\\prime}_ 2=\\text{我})\\right) * p(label^{\\prime}=\\text{爱}) \\\\<br>\n\\alpha_{5}(label^{\\prime}_ 5=\\epsilon) &amp;= \\left(\\alpha_{4}(label^{\\prime}_ 5=\\epsilon) + \\alpha_{4}(label^{\\prime}_ 4=\\text{爱})\\right) * p(label^{\\prime}=\\epsilon)<br>\n\\end{aligned}<br>\n\\end{equation}</p>\n<br>\n<p>当第$s$个$label^{\\prime}$是$\\epsilon$时，有两个转换来源；当是普通字符时，有三个转换来源。<strong>还有一个要注意的是，当相邻两个字符是相同的时候，也只有两个转换来源</strong>。如下图：</p>\n<p><img src=\"/images/ObjectDetection/CTC_forward2.png\" alt=\"CTC Forward2\"></p>\n<center style=\"font-size:14px;color:#C0C0C0\">Figure4, CTC Forward 2</center>\n<p>这样，我们可以写出针对$label^{\\prime}$的转换方程，为了简写，用$l$代替$label$：</p>\n<p>\\begin{equation}<br>\n\\alpha_t(l^{\\prime}_s)=<br>\n\\begin{cases}<br>\n\\left[\\alpha _{t-1}(l^{\\prime}_s) + \\alpha _{t-1}(l^{\\prime} _{s-1})\\right] * p(l^{\\prime}_s), \\ \\ if \\ \\ l^{\\prime}_s=\\epsilon \\ \\ or \\ \\ l^{\\prime}_s=l^{\\prime} _{s-2}<br>\n\\\\<br>\n\\\\<br>\n\\left[\\alpha _{t-1}(l^{\\prime}_s) + \\alpha _{t-1}(l^{\\prime} _{s-1}) + \\alpha _{t-1}(l^{\\prime} _{s-2})\\right] * p(l^{\\prime}_s), \\ \\ otherwise<br>\n\\end{cases}<br>\n\\end{equation}</p>\n<h4 id=\"4-2-后向算法\">4.2. 后向算法</h4>\n<p>后向算法与前向算法的思路一模一样，在这里不再赘述。</p>\n<h2 id=\"Inference-and-Beam-Search\">Inference and Beam Search</h2>\n<p><a href=\"https://zhuanlan.zhihu.com/p/36029811?group_id=972420376412762112\">未待完续</a></p>\n<h2 id=\"Reference\">Reference</h2>\n<ul>\n<li><a href=\"https://distill.pub/2017/ctc/\">https://distill.pub/2017/ctc/</a></li>\n<li><a href=\"https://towardsdatascience.com/intuitively-understanding-connectionist-temporal-classification-3797e43a86c\">https://towardsdatascience.com/intuitively-understanding-connectionist-temporal-classification-3797e43a86c</a></li>\n<li><a href=\"https://www.youtube.com/watch?v=UMxvZ9qHwJs\">https://www.youtube.com/watch?v=UMxvZ9qHwJs</a></li>\n</ul>\n","categories":["Computer Vision"],"tags":["Text Recognition","Loss"]},{"title":"BatchNormalization and LayerNormalization","url":"/posts/BatchNormalization%20and%20LayerNormalization/","content":"<blockquote>\n<p>This post is to introduce Batch Normalization and Layer Normaliztion, which are of the $\\textit{regularization}$ methods in $\\textit{Deep Learning}$.</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"Regularization\">Regularization</h2>\n<p>Deep learning can be very powerful since the stacked deeper layers. Thus it’s easy to overfitt and has poor performance on unseen data. To avoid that, several regularization methods are been proposed. And this post will focus on two methods, namely $\\textrm{Batch Normalization}$ and $\\textrm{Layer Normalization}$.</p>\n<h2 id=\"Batch-Normalization\">Batch Normalization</h2>\n<p>Let’s assume that we want to train a fully connected neural network, and we add a batch normalization layer into the net. We insert it between the activation layer and input layer like follow figure.</p>\n<p><img src=\"/images/Tricks/batch_norm.png\" alt=\"batch norm\"></p>\n<center style=\"font-size:14px;color:#C0C0C0\">Figure1</center>\n<p><strong>Firstly, we’ll discuss the train period.</strong></p>\n<p>As the name implies, we need to calculate <code>mean</code> value and <code>standard variation</code> value for each batch train data. Apparently, these two variables are <code>vector</code>. Assume previous layer has 100 neurons, then the mean and std are both 100 dimension.</p>\n<p>The input shape of bacth normalization layer is (batch_size, 100), and use <code>X</code> to represent. So, when training with batch data, we do follow calculation in normalization layer for each batch. <code>i</code> is the number of batch, and the computation is element wise.</p>\n<p>$$<br>\nX_i^{\\prime} = \\frac{X - \\mu_i}{\\sigma_i}<br>\n$$</p>\n<p>After that, we use another two values $\\gamma$ and $\\beta$ to do another calculation. These two parameters are learnable, which means that they’ll be fitted with data in the training period like parameters <code>W</code> and <code>b</code>. The calculation is as follow:</p>\n<p>$$<br>\nX_i^{\\prime \\prime} = \\gamma X_i^{\\prime} + \\beta<br>\n$$</p>\n<p>$X_i^{\\prime \\prime}$ will be sent to next layer doing $WX_i^{\\prime \\prime} + b$.</p>\n<p>Now, how does batch normalization do during test period? There has no <code>mean</code> value and <code>std</code> for test data, since no batch. What we do is to use the $\\mu_i$ and $\\sigma_i$, which are calculated in batch train period time. Use these values to do weight average. Bigger the batch number is, higher the corresponding weight is.</p>\n<h2 id=\"Layer-Normalization\">Layer Normalization</h2>\n<p>Unlike batch normalization using each batch data to estimate $\\mu$ and $\\sigma$, layer normalization use the units of a layer. The mean value is the avearge of one layer’s units value, so as the standard variation. The equation is as follow:<br>\n$$<br>\n\\mu_i = \\frac{\\sum_{j=1}^H a_H}{H} \\\\<br>\n$$</p>\n<p>Other setting and steps are same as before.</p>\n<h2 id=\"Reference\">Reference</h2>\n<ul>\n<li><a href=\"https://www.youtube.com/watch?v=BZh1ltr5Rkg\">https://www.youtube.com/watch?v=BZh1ltr5Rkg</a></li>\n</ul>\n"},{"title":"Spelling Error Correction with Soft-Masked BERT","url":"/posts/paper_spelling_error_correction/","content":"<blockquote>\n<p>Recently, I want to learn how to build a knowledge graph. In the period, I realize that <code>spelling error correction</code> is one of the most important links. So, I should find a paper, do some reading and take notes about it.</p>\n</blockquote>\n<a id=\"more\"></a>\n<h1>Challenges</h1>\n<p>For the <code>Spelling Error Correction for Chinese Character</code>, there are mainly two challenges, displayed as follow:</p>\n<ul>\n<li>First, some mistaken is produces by written. E.g. :\n<ul>\n<li>Wrong: 埃及有金子塔。Egypt has golden towers.</li>\n<li>Correct: 埃及有金字塔。Egypt has pyramids.</li>\n<li>For this condition, we could correct it with the <code>world knowledge</code>.</li>\n</ul>\n</li>\n<li>Another situation occurs when we need to correct it with <code>inference</code>. E.g:\n<ul>\n<li>Wrong: 他的求胜欲很强，为了越狱在挖洞。 He has a strong desire to win and is digging for prison breaks</li>\n<li>Correct: 他的求生欲很强，为了越狱在挖洞。 He has a strong desire to survive and is digging for prison breaks.</li>\n</ul>\n</li>\n</ul>\n<h1>Past Methods</h1>\n<p>It exists mainly two categories methods, namely <code>traditional machine learning</code> and <code>deep learning</code>.</p>\n<p>Some methods are displayed as below:</p>\n<ol>\n<li>a unified framework, which is consists of a pipeline of error detection, candidate generation and final candidate selection by traditional machine learning.</li>\n<li>a <code>Seq2Seq</code> model with copy mechanism which transforms an input sentence into a new sentence with spelling errors corrected.</li>\n<li>Bert based model. The dataset to fine-tuning the Bert can be generated by <code>a large confusion table</code>. In the inference period, Bert predict the most probability character for each position.</li>\n</ol>\n<p>In the above methods, we can get awesome accuracy with <code>Bert</code>. However, it seems that the result could be better with some change. In the origin bert, the model randomly select 15% words to mask, which results the model only learn the distribution of masked token and choose not to make any correction.</p>\n<h1>Proposed method</h1>\n<p>The proposed method in this paper is also Bert based. To address the aforementioned issue, the proposed model contains two network, which is detection network and another is correction network.</p>\n<p>Below is the architecture of proposed model: <code>Soft-Masked BERT</code></p>\n<p><img src=\"/images/soft-masked-bert-arch.jpg\" alt=\"model architecture\"><center style=\"font-size:14px;color:#C0C0C0\">model architecture</center></p>\n<p>As the figure illustrates, the model mainly contains two network. The correction network is <code>a Bi-GRU</code> network that predicts the probability whether the character is error for each position. And the correction network is the same as former Bert.</p>\n<p><strong>Next, we’ll dive into the detail of training method of the <code>Soft-Masked BERT</code>.</strong></p>\n<ol>\n<li>Firstly, we should creates an embedding for each character in the input sentence, which is referred as the <code>input embedding</code>.</li>\n<li>Next, we send the input embedding to <code>detection network</code> and get the output of probability of errors for the character in each position.</li>\n<li>Now, we have the probability indicating whether it’s error in each position. We do weighted sum for the <code>input embedding</code> and <code>[MASK] embedding</code> by the error probabilities.\n<ul>\n<li><strong>To explain clearly, we can look the <code>architecture illustration</code> above. We take the <code>3rd position</code> for the example.</strong></li>\n<li>With the detection network, we get the error probability of this position, denoted as $p_3$, which indicates how much the character in this position would be error. Therefore, the correct probability of the position is $1 - p_3$.</li>\n<li>Meanwhile, we have the embedding of the <code>3rd position character</code> and <code>[MASK] token</code>. So we can do weighted sum for these two embedding, and the weight is just the $p_3$ and $1 - p_3$.</li>\n</ul>\n</li>\n<li>Use the output of detection model as the input of the next correction model.</li>\n<li>There is also a residual connection between the input embedding and the output of correction model. The combination of them will be sent to the softmax layer to predict the max probability of the character, which should be put on this position.</li>\n</ol>\n<h2 id=\"Training\">Training</h2>\n<p>This model is training end-to-end, although it contains two sub-model.</p>\n<p>And the objective function for these two task are both <code>cross entropy</code>. To learning on a better way, this paper use a coefficient to combine these two loss, which is described as below:</p>\n<p>\\begin{equation}<br>\n\\boldsymbol \\ell_{total} = \\lambda \\cdot \\boldsymbol \\ell_{c}+(1-\\lambda) \\cdot \\boldsymbol \\ell_{d}<br>\n\\end{equation}</p>\n<p>where $\\boldsymbol \\ell_d$ is the objective for training of the detection network, and $\\boldsymbol \\ell_c$ is the objective for training of the correction network, which is also the final decision, and $\\lambda$ is the coefficient.</p>\n<h1>Reference</h1>\n<ul>\n<li><a href=\"https://arxiv.org/abs/2005.07421\">https://arxiv.org/abs/2005.07421</a>, origin paper</li>\n</ul>\n","categories":["Natural Language Processing"],"tags":["Paper Reading","Spelling Error Correction"]},{"title":"LoRA Explained","url":"/posts/LoRA_Explained/","content":"<blockquote>\n<p>近些时间，大模型如雨后春笋般，突的一下，进入公众视野，诸如语言领域的ChatGPT，或是图像领域的Stable Diffusion。它们在各自领域上带给用户不俗的使用体验。在算法应用开发的角度，我们更关心能不能在特定的算法环境中使用上这些先进的大模型，而庞大的模型参数量为这个问题蒙上一些不确定性。本文要介绍的<code>LoRA</code>无疑是为大模型的训练提供了一种新的可能。</p>\n</blockquote>\n<a id=\"more\"></a>\n<p>近些时间，大模型如雨后春笋般，突的一下，进入公众视野，诸如语言领域的<code>ChatGPT</code>，或是图像领域的<code>Stable Diffusion</code>。它们在各自领域上带给用户不俗的使用体验。同时，也不禁令人思考，<code>AIGC</code>到底能再往前进化到何种程度？</p>\n<p>在<code>ChatGPT</code>如日中天，鼎沸到在食堂排队都能听到其他同事乐此不疲地讨论时，我对它的“落地”并不抱有期待。因为在算法应用开发的角度，我们更关心能不能在特定的算法环境中使用上这些先进的大模型，而庞大的模型参数量为这个问题蒙上一些不确定性。</p>\n<h2 id=\"Background\">Background</h2>\n<h4 id=\"LLM-Parameters\">LLM Parameters</h4>\n<table>\n<thead>\n<tr>\n<th><strong>公司</strong></th>\n<th><strong>模型</strong></th>\n<th><strong>参数量（Bilion）</strong></th>\n<th><strong>计算资源</strong></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>OpenAI</td>\n<td>GPT-3</td>\n<td>175</td>\n<td>30000+ A100</td>\n</tr>\n<tr>\n<td>Google</td>\n<td>PaLM-E</td>\n<td>562</td>\n<td>/</td>\n</tr>\n<tr>\n<td>Meta</td>\n<td>LLaMA</td>\n<td>7/13/33/65</td>\n<td>2048 A100 for 5 months</td>\n</tr>\n</tbody>\n</table>\n<p><font size=2><strong>注：</strong><code>bert-base</code>的参数量是<code>110 milion</code></font></p>\n<p>基于拥有如此庞大参数量的大模型，在进行下游任务的<code>fine-tuning</code>时，更新<code>LLM</code>的全部参数需要大量的计算资源。</p>\n<h4 id=\"What’s-LoRA\">What’s LoRA</h4>\n<p><a href=\"https://arxiv.org/abs/2106.09685\">LoRA</a>，即<code>low-rank adapation</code>的缩写，它是一种应用在<code>LLM fine-tuning</code>阶段的训练方式。它能帮助以较少的计算资源和开销进行<code>LLM fine-tuning</code>，比较知名的项目有：</p>\n<ol>\n<li><a href=\"https://github.com/tloen/alpaca-lora\">Alpaca-LoRA</a></li>\n<li><a href=\"https://github.com/cloneofsimo/lora\">Low-rank Adaptation for Fast Text-to-Image Diffusion Fine-tuning</a></li>\n</ol>\n<p>基于<code>LoRA fine-tuning</code>的模型性能没有过多降低。在论文的实验部分，甚至还有一些任务反超了<code>fully fine-tuned model</code>。</p>\n<h2 id=\"Related-Works\">Related Works</h2>\n<h4 id=\"Adding-adapater-layers\">Adding adapater layers</h4>\n<p>该类方法的主要思想就是在大模型中新增一些<code>adapter layers</code>，在<code>fine-tuning</code>过程中，仅更新这些新增的参数，避免对大模型整体参数的更新，以达到降低计算开销的目的。以下为部分工作：</p>\n<ul>\n<li>2017，<a href=\"http://arxiv.org/abs/1705.08045\">Learning multiple visual domains with residual adapters.</a></li>\n<li>2019，<a href=\"http://arxiv.org/abs/1902\">Parameter-Efficient Transfer Learning for NLP.</a></li>\n<li>2020，<a href=\"https://aclanthology.org/2020.findings-emnlp.41\">Exploring versatile generative language model via parameter-efficient transfer learning.</a></li>\n</ul>\n<p>严格来说，<code>LoRA</code>也属于这种方式，但是相比于上述工作，它在推理时的速度并不会因为新增的参数而降低，后续会详细介绍它的计算方式。</p>\n<h4 id=\"Optimizing-the-input-word-embedding\">Optimizing the input word embedding</h4>\n<p>比较新颖的方法，<code>Prefix-Tuning</code>旨在<code>Embedding Layer</code>增加额外参数，冻结剩余网络参数，以进行下游任务的训练。</p>\n<ul>\n<li>2021，<a href=\"https://arxiv.org/pdf/2101.00190.pdf\">Prefix-Tuning: Optimizing Continuous Prompts for Generation</a></li>\n</ul>\n<h2 id=\"LoRA-Method\">LoRA Method</h2>\n<h4 id=\"Intrinsic-Dimension\">Intrinsic Dimension</h4>\n<p><img src=\"/images/LoRA/swiss_roll_data.png\" alt=\"Swiss roll data\"><center style=\"font-size:14px;color:#C0C0C0\">Swiss roll data curves, from <a href=\"https://twitter.com/lightonio/status/1240687522608373760\">https://twitter.com/lightonio/status/1240687522608373760</a></center></p>\n<p>From <a href=\"https://en.wikipedia.org/wiki/Intrinsic_dimension\">Wikipidia</a></p>\n<blockquote>\n<p>The intrinsic dimension for a data set can be thought of as the number of variables needed in a minimal representation of the data.</p>\n</blockquote>\n<p><a name=\"jaT4G\"></a></p>\n<h4 id=\"Fine-tune-LLM\">Fine-tune LLM</h4>\n<p>我们都知道，有监督神经网络的训练范式大多基于<strong>梯度下降</strong>，即一轮<code>batch data</code>过后，通过本轮数据计算<code>loss</code>更新网络参数$W$。假定当前轮为第$t$，即：</p>\n<p>$$<br>\n\\begin{equation}<br>\nW_{t+1} = W_t - lr * \\Delta{W_t}<br>\n\\end{equation}<br>\n$$<br>\n对于模型的训练，其本质是参数$W$的不断更新，记初始参数为$W_0$，训练结束得到的参数为$W_T$。对于<code>LLM</code>来说，$W_0$代表作为<code>Pretrained-model</code>的参数，通过多轮的训练，经历多个$\\Delta{W}$的更新后得到$W_T$。在更新的过程中，有：</p>\n<p>$$<br>\n\\begin{equation}<br>\n\\begin{gathered}<br>\nW_1 = W_0 - lr * \\Delta{W_0} \\\\<br>\nW_2 = W_1 - lr * \\Delta{W_1} \\\\<br>\nW_3 = W_2 - lr * \\Delta{W_2} \\\\<br>\n\\ldots \\\\<br>\nW_T = W_{T-1} - lr * \\Delta{W_{T-1}}<br>\n\\end{gathered}<br>\n\\iff<br>\nW_T = W_0 - lr * (\\Delta{W_0} + \\Delta{W_1} + \\cdots + \\Delta{W_{T-1}})<br>\n\\end{equation}<br>\n$$</p>\n<p>从这个角度来看，对模型<code>fine-tuning</code>的过程就像是学习一个适应<strong>特定任务</strong>的$\\Delta{W}$，结合$W_0$及$\\Delta{W}$进行推理，如图1所示。因此，若将$\\Delta{W}$作为可训练的参数，<code>fine-tuning LLM</code>即转化为对$\\Delta{W}$的拟合。</p>\n<p><img src=\"/images/LoRA/before.png\" alt=\"图1\"></p>\n<center style=\"font-size:14px;color:#C0C0C0\">图1</center>\n<h4 id=\"Introduce-LoRA\">Introduce LoRA</h4>\n<p>有<a href=\"https://arxiv.org/abs/2012.13255\">论文</a>在实验对比的过程中，发现<code>LLM</code>的参数有着较低的$\\text{Intrinsic Demension}$，受此启发，<code>LoRA</code>的作者假定$\\Delta{W}$也存在这种特性。</p>\n<p>From <a href=\"https://arxiv.org/abs/2106.09685\">LoRA Paper</a></p>\n<blockquote>\n<p>Inspired by this, we hypothesize the updates to the weights also have a low “intrinsic rank” during adapation.</p>\n</blockquote>\n<p>若$\\Delta{W}$存在较低的$\\text{Intrinsic Rank}$，可以对其进行<strong>矩阵分解</strong>$\\left(\\text{Matrix Factorization}\\right)$，即：<br>\n$$<br>\n\\begin{equation}<br>\n\\Delta{W} = BA<br>\n\\end{equation}<br>\n$$</p>\n<p>$\\Delta{W} \\in \\mathbb{R^{d*k}}, B \\in \\mathbb{R^{d*r}}, A \\in \\mathbb{R^{r*k}}, r \\ll \\min(d, k)$，使用$(3)$式表示$\\Delta{W}$之后，参与学习的参数量得倒缩减，由$O(d * k)$缩减至$O((d + k) * r)$。</p>\n<p><img src=\"/images/LoRA/after.png\" alt=\"图2\"></p>\n<center style=\"font-size:14px;color:#C0C0C0\">图2</center>\n<h2 id=\"Practice\">Practice</h2>\n<p><code>LoRA</code>的想法看起来十分简单，目前开源社区有两方实现其工程代码。</p>\n<ul>\n<li><a href=\"https://github.com/microsoft/LoRA\">论文作者</a></li>\n<li><a href=\"https://github.com/huggingface/peft\">hugging face PEFT</a></li>\n</ul>\n<p>后者主要对在<code>PyTorch FSDP</code>的训练模式上进行调整，但在使用形式上没有区别，以下基于<strong>论文作者</strong>的版本进行介绍。<br>\n<a name=\"xfdTU\"></a></p>\n<h4 id=\"Quick-Start\">Quick Start</h4>\n<p><strong>安装</strong></p>\n<p><code>pip install git+https://github.com/microsoft/LoRA</code></p>\n<p><strong>使用</strong></p>\n<ul>\n<li>创建</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># ===== Before =====</span></span><br><span class=\"line\">layer = nn.Linear(in_features, out_features)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># ===== After ======</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> loralib <span class=\"keyword\">as</span> lora</span><br><span class=\"line\"><span class=\"comment\"># Add a pair of low-rank adaptation matrices with rank r=16</span></span><br><span class=\"line\">layer = lora.Linear(in_features, out_features, r=<span class=\"number\">16</span>)</span><br></pre></td></tr></table></figure>\n<ul>\n<li>循环</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> loralib <span class=\"keyword\">as</span> lora</span><br><span class=\"line\">model = BigModel()</span><br><span class=\"line\"><span class=\"comment\"># This sets requires_grad to False for all parameters without the string &quot;lora_&quot; in their names</span></span><br><span class=\"line\">lora.mark_only_lora_as_trainable(model)</span><br><span class=\"line\"><span class=\"comment\"># Training loop</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> batch <span class=\"keyword\">in</span> dataloader:</span><br><span class=\"line\">   ...</span><br></pre></td></tr></table></figure>\n<ul>\n<li>保存模型</li>\n</ul>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># ===== Before =====</span></span><br><span class=\"line\">torch.save(model.state_dict(), checkpoint_path)</span><br><span class=\"line\"><span class=\"comment\"># ===== After =====</span></span><br><span class=\"line\">torch.save(lora.lora_state_dict(model), checkpoint_path)</span><br></pre></td></tr></table></figure>\n<h4 id=\"LoRA-Layer\">LoRA Layer</h4>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">LoRALayer</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span>(<span class=\"params\"></span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        self, </span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        r: <span class=\"built_in\">int</span>, </span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        lora_alpha: <span class=\"built_in\">int</span>, </span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        lora_dropout: <span class=\"built_in\">float</span>,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        merge_weights: <span class=\"built_in\">bool</span>,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">    </span>):</span></span><br><span class=\"line\">        self.r = r</span><br><span class=\"line\">        self.lora_alpha = lora_alpha</span><br><span class=\"line\">        <span class=\"comment\"># Optional dropout</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> lora_dropout &gt; <span class=\"number\">0.</span>:</span><br><span class=\"line\">            self.lora_dropout = nn.Dropout(p=lora_dropout)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            self.lora_dropout = <span class=\"keyword\">lambda</span> x: x</span><br><span class=\"line\">        <span class=\"comment\"># Mark the weight as unmerged</span></span><br><span class=\"line\">        self.merged = <span class=\"literal\">False</span></span><br><span class=\"line\">        self.merge_weights = merge_weights</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Linear</span>(<span class=\"params\">nn.Linear, LoRALayer</span>):</span></span><br><span class=\"line\">    <span class=\"comment\"># LoRA implemented in a dense layer</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span>(<span class=\"params\"></span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        self, </span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        in_features: <span class=\"built_in\">int</span>, </span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        out_features: <span class=\"built_in\">int</span>, </span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        r: <span class=\"built_in\">int</span> = <span class=\"number\">0</span>, </span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        lora_alpha: <span class=\"built_in\">int</span> = <span class=\"number\">1</span>, </span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        lora_dropout: <span class=\"built_in\">float</span> = <span class=\"number\">0.</span>,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        fan_in_fan_out: <span class=\"built_in\">bool</span> = <span class=\"literal\">False</span>, <span class=\"comment\"># Set this to True if the layer to replace stores weight like (fan_in, fan_out)</span></span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        merge_weights: <span class=\"built_in\">bool</span> = <span class=\"literal\">True</span>,</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">        **kwargs</span></span></span><br><span class=\"line\"><span class=\"function\"><span class=\"params\">    </span>):</span></span><br><span class=\"line\">        nn.Linear.__init__(self, in_features, out_features, **kwargs)</span><br><span class=\"line\">        LoRALayer.__init__(self, r=r, lora_alpha=lora_alpha, lora_dropout=lora_dropout,</span><br><span class=\"line\">                           merge_weights=merge_weights)</span><br><span class=\"line\"></span><br><span class=\"line\">        self.fan_in_fan_out = fan_in_fan_out</span><br><span class=\"line\">        <span class=\"comment\"># Actual trainable parameters</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> r &gt; <span class=\"number\">0</span>:</span><br><span class=\"line\">            self.lora_A = nn.Parameter(self.weight.new_zeros((r, in_features)))</span><br><span class=\"line\">            self.lora_B = nn.Parameter(self.weight.new_zeros((out_features, r)))</span><br><span class=\"line\">            self.scaling = self.lora_alpha / self.r</span><br><span class=\"line\">            <span class=\"comment\"># Freezing the pre-trained weight matrix</span></span><br><span class=\"line\">            self.weight.requires_grad = <span class=\"literal\">False</span></span><br><span class=\"line\">        self.reset_parameters()</span><br><span class=\"line\">        <span class=\"keyword\">if</span> fan_in_fan_out:</span><br><span class=\"line\">            self.weight.data = self.weight.data.T</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">reset_parameters</span>(<span class=\"params\">self</span>):</span></span><br><span class=\"line\">        nn.Linear.reset_parameters(self)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"built_in\">hasattr</span>(self, <span class=\"string\">&#x27;lora_A&#x27;</span>):</span><br><span class=\"line\">            <span class=\"comment\"># initialize A the same way as the default for nn.Linear and B to zero</span></span><br><span class=\"line\">            nn.init.kaiming_uniform_(self.lora_A, a=math.sqrt(<span class=\"number\">5</span>))</span><br><span class=\"line\">            nn.init.zeros_(self.lora_B)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">train</span>(<span class=\"params\">self, mode: <span class=\"built_in\">bool</span> = <span class=\"literal\">True</span></span>):</span></span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">T</span>(<span class=\"params\">w</span>):</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> w.T <span class=\"keyword\">if</span> self.fan_in_fan_out <span class=\"keyword\">else</span> w</span><br><span class=\"line\">        nn.Linear.train(self, mode)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.merge_weights <span class=\"keyword\">and</span> self.merged:</span><br><span class=\"line\">            <span class=\"comment\"># Make sure that the weights are not merged</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> self.r &gt; <span class=\"number\">0</span>:</span><br><span class=\"line\">                self.weight.data -= T(self.lora_B @ self.lora_A) * self.scaling</span><br><span class=\"line\">            self.merged = <span class=\"literal\">False</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">eval</span>(<span class=\"params\">self</span>):</span></span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">T</span>(<span class=\"params\">w</span>):</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> w.T <span class=\"keyword\">if</span> self.fan_in_fan_out <span class=\"keyword\">else</span> w</span><br><span class=\"line\">        nn.Linear.<span class=\"built_in\">eval</span>(self)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.merge_weights <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> self.merged:</span><br><span class=\"line\">            <span class=\"comment\"># Merge the weights and mark it</span></span><br><span class=\"line\">            <span class=\"keyword\">if</span> self.r &gt; <span class=\"number\">0</span>:</span><br><span class=\"line\">                self.weight.data += T(self.lora_B @ self.lora_A) * self.scaling</span><br><span class=\"line\">            self.merged = <span class=\"literal\">True</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span>(<span class=\"params\">self, x: torch.Tensor</span>):</span></span><br><span class=\"line\">        <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">T</span>(<span class=\"params\">w</span>):</span></span><br><span class=\"line\">            <span class=\"keyword\">return</span> w.T <span class=\"keyword\">if</span> self.fan_in_fan_out <span class=\"keyword\">else</span> w</span><br><span class=\"line\">        <span class=\"keyword\">if</span> self.r &gt; <span class=\"number\">0</span> <span class=\"keyword\">and</span> <span class=\"keyword\">not</span> self.merged:</span><br><span class=\"line\">            result = F.linear(x, T(self.weight), bias=self.bias)</span><br><span class=\"line\">            <span class=\"keyword\">if</span> self.r &gt; <span class=\"number\">0</span>:</span><br><span class=\"line\">                result += (self.lora_dropout(x) @ self.lora_A.T @ self.lora_B.T) * self.scaling</span><br><span class=\"line\">            <span class=\"keyword\">return</span> result</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">return</span> F.linear(x, T(self.weight), bias=self.bias)</span><br></pre></td></tr></table></figure>\n","tags":["Efficient Framework","Large Language Model"]},{"title":"BERT Explained","url":"/posts/BERT_Explained/","content":"<blockquote>\n<p>BERT, which means $Bidirectional \\ Encoder \\ Representations \\ from \\ Transformers$, is one kind of SOAT models in natural language preprocessing over multiple tasks. In this arctile, I want to note my opnion of this model architecture and its training method.</p>\n</blockquote>\n<a id=\"more\"></a>\n<h2 id=\"Beginning\">Beginning</h2>\n<p>BERT is proposed in 2018, from the paper <a href=\"https://arxiv.org/abs/1810.04805\">BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding</a>. We can know its model architecture derived from Transformer, which is also proposed by Google in 2017 from the paper <a href=\"https://arxiv.org/abs/1706.03762\">Attention Is All You Need</a>. Every time I mention these two amazing papers, I can hardly conceal my excitement. They provide creative ideas for computers to understand natural language. I even think all practitioners related to NLP should have basic knowledge of $BERT$.</p>\n<p>To explain $BERT$ clearly, I plan to introduce Machine Translation task, and its most common model architecture Sequence to Sequence firstly. Then, I’ll introduce the Transformer, which is one kind of <code>Seq2Seq</code> models but involving <code>Attention Mechanism</code> and the performance has been greatly imporved. Finally, we’ll focus on BERT.</p>\n<p>This article is my summary for related work and hope it’s helpful. Simultaneously, there are so many awesome articles and I list them at the end part <code>Reference</code>. Thanks for these authors’ excellent work to make all the core concepts clear.</p>\n<h2 id=\"Sequence-to-Sequence\">Sequence to Sequence</h2>\n<p>$Seq2Seq$最常见的应用常见便是<code>机器翻译</code>，在过去的几年中，这个领域的研究有长足的突破，很多商业软件比如谷歌翻译、有道翻译等等达到了非常好的翻译效果。简单来说，机器翻译任务实现的是不同国家或者地区间语言的转换，能帮助人们更加畅通的沟通。</p>\n<p>除了上述提到的机器翻译，$Seq2Seq$理论上来说适用于任何序列文本间的转换，比如编程语言间的转换，从<code>C++</code>转换到<code>Golang</code>。甚至，那些本就不存在的语言，但是只要有着一定量的训练数据，$Seq2Seq$总能为我们发现源语言与目标语言的映射关系，并且帮助我们建立这种关系。</p>\n<p>首先，让我们忘记$Seq2Seq$架构，想一想如何描述机器翻译这个场景。彼时存在输入文本$\\mathbf{x}={x_1, x_2, \\ldots, x_n}$，通过翻译之后，将会得到另外一组序列文本$\\mathbf{y}={y_1, y_2, \\ldots, y_m}$。可以使用概率 $p(\\mathbf{y} \\mid \\mathbf{x})$ 表示：<br>\n$$<br>\n\\mathbf{y}^{*}=\\arg \\max_{\\mathbf{y}} p(\\mathbf{y} \\mid \\mathbf{x})<br>\n$$<br>\n理论上$\\mathbf{y}$的空间是无穷大的，即可能出现很多个翻译结果，但最后需要的是那个概率最大的输出。</p>\n<p>接着，将上述的式子进行改写，加入模型的参数$\\theta$，如下所示：<br>\n$$<br>\n\\mathbf{y}^{*}=\\arg \\max_{\\mathbf{y}} p(\\mathbf{y} \\mid \\mathbf{x}, \\theta)<br>\n$$<br>\n现在，我们已经定义了一个关于<code>机器翻译场景</code>的概率模型。其实，和它相似的概率模型还有很多，比如实体识别，同样如上述定义，只不过输入$\\mathbf{x}$与输出$\\mathbf{y}$的长度是一样的。之后要考虑的问题主要围绕三个方面：</p>\n<ol>\n<li>如何建模，即参数$\\theta$长什么样子？</li>\n<li>如何去训练参数？</li>\n<li>如何推理？</li>\n</ol>\n<p>实际上，对于大多数涉及到概率模型去解决业务问题的，无论是基于联合概率分布的比如<code>HMM</code>或是基于条件概率分布的比如<code>CRF</code>或是之后要介绍的<code>Seq2Seq</code>，最后求解的时候就是这三板斧。</p>\n<h1>Reference</h1>\n<ul>\n<li><a href=\"https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html#main_content\">The best and intuitive blog I have ever read about Seq2Seq, Attention, Transformers and etc. Some parts of my article can be regarded as the chinese version of this blog.</a></li>\n<li><a href=\"http://jalammar.github.io/illustrated-transformer/\">Illustrated Transformer</a></li>\n<li><a href=\"http://zh.gluon.ai/chapter_natural-language-processing/seq2seq.html\">The best practical and theoretical Deep Learning Book, Dive into DL</a></li>\n</ul>\n","categories":["Natural Language Processing"],"tags":["Transformers","BERT Family","Sequence Model"]},{"title":"LSTM Explained","url":"/posts/LSTM_Explained/","content":"<blockquote>\n<p>在时序相关或者文本相关的任务中，人们常常会使用<code>RNN-Based</code>的序列模型，本文将主要介绍<code>LSTM</code>涉及到的一些知识点。主要参考几篇优秀的博文，链接将放在最后的<a href=\"#jump\">Reference</a>中，感兴趣的建议直接阅读原文🚘。</p>\n</blockquote>\n<a id=\"more\"></a>\n<p>为了避免<code>Vanilla RNN</code>在输入长文本后带来的梯度消失问题，研究者提出了<code>LSTM unit</code>，即<code>long-short term memory unit</code>，使用它们作为整个序列模型中的最小单元。</p>\n<p>在<code>LSTM unit</code>中共存在两种<code>state</code>，一类是<code>hidden state</code>，另一类是<code>cell state</code>。同时，引入了<code>门机制</code>，分别为<code>Forget Gate</code>、<code>Update Gate/Input Gate</code>以及<code>Output Gate</code>。在每一个<code>time step</code>时，模型通过<code>上述的门机制</code>决定应该存放哪些信息，同时过滤掉哪些信息。</p>\n<p>首先，为了阐明<code>LSTM unit</code>的计算机制，先对其内部架构进行一定的了解，如下图所示：</p>\n<p><img src=\"https://miro.medium.com/max/700/0*exoKHMF9vYA3ZJvJ.png\" alt=\"LSTM unit\"><center style=\"font-size:14px;color:#C0C0C0\">Fig 1. LSTM unit, from <a href=\"https://miro.medium.com/max/700/0*exoKHMF9vYA3ZJvJ.png\">https://miro.medium.com/max/700/0*exoKHMF9vYA3ZJvJ.png</a></center></p>\n<p>通过<code>Fig 1</code>，我们可以预览到<code>LSTM</code>传播时数据的大致流通过程。更近一步的，通过以下动图可以一目了然地观察到数据是怎么在一个<code>unit</code>中流动的。</p>\n<p><img src=\"https://miro.medium.com/proxy/1*goJVQs-p9kgLODFNyhl9zA.gif\" alt=\"Long Short Term Memory with its gates\"><center style=\"font-size:14px;color:#C0C0C0\">Fig 2. Data flow in LSTM unit, from <a href=\"https://miro.medium.com/proxy/1*goJVQs-p9kgLODFNyhl9zA.gif\">https://miro.medium.com/proxy/1*goJVQs-p9kgLODFNyhl9zA.gif</a></center></p>\n<p>可以清晰地看到，在时间步<code>t</code>时，<code>unit</code>接收来自时间步<code>t-1</code>的$c_{t-1}$与$h_{t-1}$，经过若干次的线性变化以及point-wise操作后，输出<code>c_t</code>与<code>h_t</code>。下面将具体介绍每个门机制的运行过程以及个人对于该设计的理解。</p>\n<p>首先，我们可以将内部计算中涉及到门计算的部分分为以下几种。</p>\n<p><img src=\"https://miro.medium.com/max/700/0*G474BVfgtu5ZE4ai\" alt=\"LSTM unit with gates\"><center style=\"font-size:14px;color:#C0C0C0\">Fig 3. Three types of gates in LSTM unit, from <a href=\"https://miro.medium.com/max/700/0*G474BVfgtu5ZE4ai\">https://miro.medium.com/max/700/0*G474BVfgtu5ZE4ai</a></center></p>\n<p>其中：</p>\n<ul>\n<li>最左边的部分为<code>Forget Gate</code>;</li>\n<li>中间的部分为<code>Input Gate或Update Gate</code>;</li>\n<li>最右边的部分为<code>Output Gate</code>.</li>\n</ul>\n<h3 id=\"Forget-Gate\">Forget Gate</h3>\n<blockquote>\n<p>对于上一个时间步传递的<code>cell state</code>信息，<code>遗忘门</code>决定哪些信息需要被继续保持，哪些信息应被遗忘。</p>\n</blockquote>\n<p>假设当前所在的时间步为<code>t</code>，记当前<code>forget gate</code>的输入为$X_t$，$c_{t-1}$以及$h_{t-1}$，输出为$C_{tmp}$，根据上面动图中的计算，其相应的计算伪代码如下：</p>\n<ol>\n<li>将$X_t$与$h_{t-1}$进行<code>concatenation</code>，得到$[h_{t-1}, X_{t}]$；</li>\n<li>通过$W_{forget}$与$b_{forget}$进行线性转换，再通过<code>sigmoid</code>将计算结果转换到<code>[0, 1]</code>区间；</li>\n<li>最后，将上述输出的<code>概率向量</code>与$c_{t-1}$中保存的向量做<code>point-wise</code>乘法。</li>\n</ol>\n<p>下面是<code>Forget Gate</code>的计算公式：</p>\n<ol>\n<li>$Conbine = Concatenation(h_{t-1}, X_t)$</li>\n<li>$Z_f = Sigmoid(W_{forget} Conbine + b_{forget})$</li>\n<li>$c_{tmp} = c_{t-1} * Z_f$</li>\n</ol>\n<!-- \\begin{equation*}\n\\tag{1}\n\\label{a}\n\\begin{cases}\n    Conbine_{forget} = Concatenation(h_{t-1}, X_t) \\\\\\\\\n    O = Sigmoid(W_{forget} Conbine_{forget} + b_{forget}), \\\\\\\\\n    C_{t1} = C_{t-1} * O\n\\end{cases}\n\\end{equation*} -->\n<p>通过<code>Forget Gate</code>的一系列操作，上一个时间步的$c_{t-1}$第一次得到了更新，得到了$c_{tmp}$。我们用它表示在时间步<code>t</code>输出最终<code>cell state</code>前的中间值。</p>\n<p>我认为遗忘门运作的机制是：将之前保存的信息（存放在$h_{t-1}$）与当前时间步的输入信息（$X_t$）进行比较，进而去判断是否对$c_{t-1}$中的某些信息进行遗忘。当<code>sigmoid</code>输出的向量中某个位置输出的概率值更偏向于0，则说明$c_{t-1}$对应位置上的信息应该被遗忘；而当该位置的概率值更偏向1时，则$c_{t-1}$对应位置上的信息更应该保留。</p>\n<h3 id=\"Update-Gate-Input-Gate\">Update Gate/Input Gate</h3>\n<blockquote>\n<p><code>更新门</code>需要考虑将哪些新信息保存或者贴加到<code>cell state</code>中，并且输出到下一个时间步。</p>\n</blockquote>\n<p>在<code>Update Gate</code>中，<code>unit</code>决定<code>什么信息</code>要被更新到$c_{tmp}$中。这组门运算的输入包括：$h_{t-1}, X_t, c_{tmp}$，输出为$c_{t}$：</p>\n<ol>\n<li>第一步还是同<code>Forget Gate</code>中形式的一样，先将$X_t$与$h_{t-1}$进行<code>concatenation</code>，得到$[h_{t-1}, X_{t}]$；</li>\n<li>接下来，分别进行两次线性变换，但是各自<code>activation function</code>不同，一个为<code>sigmod</code>，而另一个则为<code>tanh</code>；</li>\n<li>最后，将两个结果进行<code>point-wise</code>的乘法，得到<code>Update Gate</code>的输出。</li>\n</ol>\n<p>同样的，下面是<code>Update Gate</code>的计算公式：</p>\n<ol>\n<li>$Conbine = Concatenation(h_{t-1}, X_t)$</li>\n<li>$Z_u = Sigmoid(W_{update1} Conbine + b_{update1})$</li>\n<li>$O_u = Tanh(W_{update2} Conbine + b_{update2})$</li>\n<li>$c_{t} = c_{tmp} + Z_u * O_u$</li>\n</ol>\n<p><code>更新门</code>中共存在两组<code>线性转化</code>的参数：$(W_{update1}, b_{update1})$以及$(W_{update2}, b_{update2})$，各自的结果转化之后相乘，再加到$c_{tmp}$上，最后得到当前时间步将要输出的<code>cell state</code>。</p>\n<h3 id=\"Output-Gate\">Output Gate</h3>\n<blockquote>\n<p><code>输出门</code>的作用在于结合各种信息，在当前的时间步做出决策，同时为下一个时间步的计算提供信息。</p>\n</blockquote>\n<p>除去上述的两组，<code>unit</code>中还剩下一组门运算，即<code>输出门</code>。它的输入包括$h_{t-1}, X_t, c_{t}$，最后的输出为$h_t$:</p>\n<ol>\n<li>第一步依旧是拼接$X_t$与$h_{t-1}$，得到$[h_{t-1}, X_{t}]$；</li>\n<li>通过$W_{output}$与$b_{output}$进行线性转换，再通过<code>sigmoid</code>将计算结果转换到<code>[0, 1]</code>区间；</li>\n<li>将$c_t$通过<code>tanh</code>运算；</li>\n<li>最后将2、3步的输出做<code>point-wise</code>的乘法，得到<code>Output Gate</code>的输出，也就是$h_t$。</li>\n</ol>\n<p>同样，下面是<code>Output Gate</code>的计算公式：</p>\n<ol>\n<li>$Conbine = Concatenation(h_{t-1}, X_t)$</li>\n<li>$Z_o = Sigmoid(W_{output} Conbine + b_{output})$</li>\n<li>$O_o = Tanh(c_t)$</li>\n<li>$h_t = Z_o * O_o$</li>\n</ol>\n<h2 id=\"总结\">总结</h2>\n<p>到此，一个<code>LSTM unit</code>中的计算流程已经走完，下面我想谈一下个人对于其中几点的理解。首先是出现了两种激活函数<code>sigmoid</code>以及<code>tanh</code>。其中，<code>sigmoid</code>共出现了3次，分别在三个门中都出现；<code>tanh</code>则是出现在<code>Update Gate</code>以及<code>Output Gate</code>中。</p>\n<p><code>sigmoid</code>能将数值缩放至[0, 1]区间，它在<code>LSTM unit</code>中的使用都是与其他向量做<code>point-wise</code>的乘法，所以我认为使用它主要是为了使<code>unit</code>在处理时能够将信息进行保存或者遗忘。</p>\n<p><code>tanh</code>能将数值缩放至[-1, 1]区间，它在<code>LSTM unit</code>中被使用时基本上是为了将<code>信息</code>转化为<code>数值</code>，在<code>Update Gate</code>中，该数值会被记录到<code>cell state</code>中，在<code>Output Gate</code>中，该数值会被转化为下一个时间步的<code>hidden state</code>。</p>\n<h2 id=\"span-id-jump-Reference-span\"><span id=\"jump\">Reference</span></h2>\n<ul>\n<li>\n<p><a href=\"https://towardsdatascience.com/illustrated-guide-to-recurrent-neural-networks-79e5eb8049c9\">Illustrated Guide to Recurrent Neural Networks</a></p>\n</li>\n<li>\n<p><a href=\"https://colah.github.io/posts/2015-08-Understanding-LSTMs/\">Understanding LSTM Networks</a></p>\n</li>\n<li>\n<p><a href=\"https://towardsdatascience.com/illustrated-guide-to-lstms-and-gru-s-a-step-by-step-explanation-44e9eb85bf21\">Illustrated Guide to LSTM’s and GRU’s: A step by step explanation</a></p>\n</li>\n<li>\n<p><a href=\"https://r2rt.com/written-memories-understanding-deriving-and-extending-the-lstm.html#recurrent-neural-networks\">Written Memories: Understanding, Deriving and Extending the LSTM</a></p>\n</li>\n<li>\n<p><a href=\"https://purnasaigudikandula.medium.com/recurrent-neural-networks-and-lstm-explained-7f51c7f6bbb9\">Recurrent Neural Networks and LSTM explained</a></p>\n</li>\n</ul>\n","categories":["Natural Language Processing"],"tags":["Sequence Model"]},{"title":"Training Objective of DDPM","url":"/posts/Training_Objective_of_DDPM/","content":"<blockquote>\n<p>很多次翻看DDPM，始终不太能理解论文中提到的$\\text{Variational Inference}$到底是如何在这个工作中起到作用。五一假期在家，无意间又刷到徐亦达老师早些年录制的理论视频，没想到其中也有介绍这部分的内容。老师的上课方式总是娓娓道来，把每一步都讲解得很仔细。本文记录一下个人对开头问题的思考。</p>\n</blockquote>\n<a id=\"more\"></a>\n<h1>Background</h1>\n<p>如果需要简略地介绍一下<a href=\"https://arxiv.org/abs/2006.11239\">DDPM</a>这个工作，可能会用以下几句话简单地描述：<code>DDPM</code>以<code>Markov</code>的形式对数据（图片）“扩散过程”建模，使用神经网络进行训练拟合，学习数据的概率分布。</p>\n<p>所以对于生成任务来说，希望从给定数据中学习到的是数据的潜在信息。比如图片生成，在给定一些图片后，模型学习到的是“正常图片长什么样子”，如：</p>\n<ol>\n<li>一张包含手机正面的图片会有【手机屏幕】；</li>\n<li>一张包含猫咪的图片会有人们观察到的猫咪模样；</li>\n<li>…</li>\n</ol>\n<p>对于图片中每个像素点和附近的像素点，进行“合理”布局，才能生成“符合人们认知的图片”。</p>\n<p><strong>图片生成</strong>能像常见的机器学习任务如分类任务、回归任务，能基于<code>maximize likelihood</code>的形式来训练么？</p>\n<p>**结论是很难，**先回顾如何做<code>maximum likelihood</code>。给定一批数据，首先需要假定数据服从的分布，接着写出似然函数，之后直接通过解析解的形式或是梯度下降的形式，求出分布。</p>\n<p>问题就出在<strong>假定分布</strong>这一步，没有人知道图片客观上服从什么分布。那如果使用神经网络直接拟合可以么？这好像也不现实，拿一张<code>512*512*3</code>的图片来说，网络输出层共有约<code>75w</code>的数值。</p>\n<p>对于图片生成还有另外一个问题，世界上的<strong>图片太多了</strong>，目之所及稍做处理，皆为图片。即便使用神经网络能拟合，最后生成的图片很难存在多样性。</p>\n<p>那目前图片生成模型都是怎么做的，比如<code>VAE</code>或是本文即将要介绍的<code>Diffusion Model</code>，它们学习的都是数据分布$p(x)$，但直接求$p(x)$这么麻烦，需要怎么做？这其实也是$\\text{Variational Inference}$的核心思想，“曲线救国”，通过引入其它分布，将原本难以优化的问题转变为可优化问题。<br>\n<a name=\"OsljP\"></a></p>\n<h1>ELOB</h1>\n<p>先把上述提到的所有背景先抛开，研究一下$p(x)$，看看能得到什么有意思的结论。</p>\n<p>a. 基于贝叶斯定理进行变换：$p(x) = \\frac{p(x, z)}{p(z\\mid x)}$，$z$是另一个随机变量；</p>\n<p>b. 对于两边同时取$\\ln$，等式依然成立，因此有：$\\ln{p(x)} = \\ln{\\frac{p(x, z)}{p(z \\mid x)}}$；</p>\n<p>c. 右边分子分母同乘以$q(z)$：<br />$\\ln{p(x)} = \\ln{\\frac{p(x, z) * q(z)}{p(z \\mid x) * q(z)}} = \\ln{\\left(\\frac{p(x, z)}{q(z)} * \\frac{q(z)}{p(z \\mid x)}\\right)} = \\ln{\\frac{p(x, z)}{q(z)}} + \\ln{\\frac{q(z)}{p(z \\mid x)}}$</p>\n<p>d. 再次，对于上式左右两边求关于$q(z)$的期望，等式依然成立：<br />$\\begin{equation}<br>\n\\begin{align}<br>\n&amp;\\mathbb{E}<em>{z\\sim q(z)}{[\\ln{p(x)}]} = \\mathbb{E}</em>{z\\sim q(z)}{(\\ln{\\frac{p(x, z)}{q(z)}} + \\ln{\\frac{q(z)}{p(z \\mid x)}})} \\<br>\n\\iff &amp; \\int_z q(z)\\ln{p(x)}dz = \\int_z q(z)\\ln{\\frac{p(x, z)}{q(z)}}dz + \\int_z q(z)\\ln{\\frac{q(z)}{p(z \\mid x)}}dz \\<br>\n\\iff &amp; \\ln{p(x)} = \\int_z q(z)\\ln{\\frac{p(x, z)}{q(z)}}dz + \\int_z q(z)\\ln{\\frac{q(z)}{p(z \\mid x)}}dz<br>\n\\end{align}<br>\n\\end{equation}$</p>\n<p>一系列变换后，$(1)$式是最后的推导结果，等式右边由两个项组成。第二个项$\\int_z q(z)\\ln{\\frac{q(z)}{p(z \\mid x)}}dz$，叫做<a href=\"https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence\">KL散度</a>，它被用来衡量两个分布之间的“距离”，<strong>性质是值不小于0</strong>。</p>\n<p>这样一来，通过$(1)$可以得到不等式$(2)$：<br />$\\begin{equation}<br>\n\\ln{p(x)} \\geq \\int_z q(z)\\ln{\\frac{p(x, z)}{q(z)}}dz<br>\n\\end{equation}$</p>\n<p>$(1)$式右边的第一项，同时也是$(2)$式的右边项，被学者们叫做$\\text{ELBO(Evidence Lower Bound)}$。<br>\n<a name=\"rciCk\"></a></p>\n<h1>Objective Function</h1>\n<p>上述推导的$(2)$式可以被视作“定理”一般的存在，即对于某个分布的对数形式，总可以找到它的下界。</p>\n<p>那$(2)$式可以用来做什么？在<code>Background</code>中提到，图片生成任务中的$p(x)$想要对它做<code>maximum likelihood</code>根本无法做起。目标依然是最大化$p(x)$，但有了$(2)$式，求解的目标可以转移到最大化它的下界$\\text{ELBO}$。</p>\n<p>这也是论文中提到的：</p>\n<blockquote>\n<p>This paper presents progress in diffusion probabilistic models. A diffusion probabilistic model (which we will call a “diffusion model” for brevity) is a parameterized Markov chain trained using variational inference to produce samples matching the data after finite time.</p>\n</blockquote>\n<p>接下来，回到论文中，看看是如何一步步推导出<code>DDPM</code>的优化目标。$(3)$式直接摘录于论文：<br />$\\ln{p(x)} \\geq \\int_z q(z)\\ln{\\frac{p(x, z)}{q(z)}}dz = \\mathbb{E}_{z \\sim q(z)}\\left[\\ln{\\frac{p(x,z)}{q(z)}}\\right]\\tag{2}$</p>\n<p>$\\begin{equation}<br>\n\\mathbb{E}\\left[-\\log p_\\theta\\left(\\mathbf{x}<em>0\\right)\\right] \\leq \\mathbb{E}<em>q\\left[-\\log \\frac{p</em>\\theta\\left(\\mathbf{x}</em>{0: T}\\right)}{q\\left(\\mathbf{x}_{1: T} \\mid \\mathbf{x}<em>0\\right)}\\right]=\\mathbb{E}<em>q\\left[-\\log p\\left(\\mathbf{x}<em>T\\right)-\\sum</em>{t \\geq 1} \\log \\frac{p</em>\\theta\\left(\\mathbf{x}</em>{t-1} \\mid \\mathbf{x}_t\\right)}{q\\left(\\mathbf{x}<em>t \\mid \\mathbf{x}</em>{t-1}\\right)}\\right]=: L<br>\n\\end{equation}$<br />下面一项项地对$(3)$ 进行拆解，并且将它与$(2)$比对，能帮助更好地理解：</p>\n<ol>\n<li>\n<p>$(3)$不等号左边的$\\mathbb{E}\\left[-\\log p_\\theta\\left(\\mathbf{x}<em>0\\right)\\right]$进一步化简就是$-\\log p</em>\\theta\\left(\\mathbf{x}<em>0\\right)$。其中，$p</em>\\theta\\left(\\mathbf{x}_0\\right)$便是模型要学习的最终目标：图像的分布，$\\theta$是模型的参数，$\\mathbf{x}_0$是图片；</p>\n</li>\n<li>\n<p>$(2)$式的左右两边同时加上符号，$\\geq$变为$\\leq$；</p>\n</li>\n<li>\n<p>看$(3)$不等式右边部分，$\\mathbb{E}<em>q\\left[-\\log \\frac{p</em>\\theta\\left(\\mathbf{x}<em>{0: T}\\right)}{q\\left(\\mathbf{x}</em>{1: T} \\mid \\mathbf{x}_0\\right)}\\right]$</p>\n<ol>\n<li>很明显，$q(\\mathbf{x}_{1:T} \\mid \\mathbf{x}_0)$相当于$(2)$中引入的额外分布$q(z)$。对于$z$，在生成模型中会给它一个称呼：隐变量$(\\text{latent})$。实际上，在<code>diffusion models</code>里，对$\\mathbf{x}_0$加噪后的$\\mathbf{x}_1,\\mathbf{x}_2,\\ldots, \\mathbf{x}_T$就可以看作隐变量，那不妨记作$z := {\\mathbf{x}_1,\\mathbf{x}_2,\\ldots, \\mathbf{x}_T}$；</li>\n<li>$p_\\theta\\left(\\mathbf{x}<em>{0: T}\\right) = p</em>\\theta\\left(\\mathbf{x}<em>{0}, \\mathbf{x}</em>{1}, \\ldots, \\mathbf{x}_{T}\\right)$，是关于$\\mathbf{x}_0, z$的联合概率分布，因为选用马尔代夫链建模，那么依据马尔可夫链的性质，论文定义：</li>\n</ol>\n</li>\n</ol>\n<p>$\\begin{equation}<br>\n\\begin{align}<br>\nq\\left(\\mathbf{x}<em>{1: T} \\mid \\mathbf{x}<em>0\\right)&amp;:=\\prod</em>{t=1}^T q\\left(\\mathbf{x}<em>t \\mid \\mathbf{x}</em>{t-1}\\right) \\<br>\np</em>\\theta\\left(\\mathbf{x}<em>{0: T}\\right)&amp;:=p\\left(\\mathbf{x}<em>T\\right) \\prod</em>{t=1}^T p</em>\\theta\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}_t\\right)<br>\n\\end{align}<br>\n\\end{equation}$</p>\n<ol start=\"3\">\n<li>将$(4)$带入$(3)$不等式右边的第一项，得到$L$：</li>\n</ol>\n<p>$\\begin{align}<br>\n&amp;\\mathbb{E}<em>q\\left[-\\log \\frac{p</em>\\theta\\left(\\mathbf{x}<em>{0: T}\\right)}{q\\left(\\mathbf{x}</em>{1: T} \\mid \\mathbf{x}<em>0\\right)}\\right] \\<br>\n=&amp;\\mathbb{E}<em>q\\left[-\\log \\frac{p\\left(\\mathbf{x}<em>T\\right) \\prod</em>{t=1}^T p</em>\\theta\\left(\\mathbf{x}</em>{t-1} \\mid \\mathbf{x}<em>t\\right)}{\\prod</em>{t=1}^T q\\left(\\mathbf{x}<em>t \\mid \\mathbf{x}</em>{t-1}\\right)}\\right] \\<br>\n=&amp;\\mathbb{E}<em>q\\left[-\\log p\\left(\\mathbf{x}<em>T\\right)-\\sum</em>{t \\geq 1} \\log \\frac{p</em>\\theta\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}<em>t\\right)}{q\\left(\\mathbf{x}<em>t \\mid \\mathbf{x}</em>{t-1}\\right)}\\right] := L<br>\n\\end{align}$<br />到目前为止，经过了很多轮的变换以及数学公式，先捋一遍，再往下。<br />$L$<strong>是一个替代的优化目标，</strong>$\\argmin{(L)} \\iff \\argmin{(-\\ln{p}</em>{\\theta}(\\mathbf{x}<em>0))} \\iff \\argmax{(\\ln{p}</em>{\\theta}(\\mathbf{x}_0))}$</p>\n<p>接下来，论文中对$L$进行了重写，以下步骤直接摘录自论文$\\text{Appendix A}$</p>\n<p>$\\begin{equation}\\begin{aligned} L &amp; =\\mathbb{E}<em>q\\left[-\\log \\frac{p</em>\\theta\\left(\\mathbf{x}<em>{0: T}\\right)}{q\\left(\\mathbf{x}</em>{1: T} \\mid \\mathbf{x}<em>0\\right)}\\right] \\ &amp; =\\mathbb{E}<em>q\\left[-\\log p\\left(\\mathbf{x}<em>T\\right)-\\sum</em>{t \\geq 1} \\log \\frac{p</em>\\theta\\left(\\mathbf{x}</em>{t-1} \\mid \\mathbf{x}<em>t\\right)}{q\\left(\\mathbf{x}<em>t \\mid \\mathbf{x}</em>{t-1}\\right)}\\right] \\ &amp; =\\mathbb{E}<em>q\\left[-\\log p\\left(\\mathbf{x}<em>T\\right)-\\sum</em>{t&gt;1} \\log \\frac{p</em>\\theta\\left(\\mathbf{x}</em>{t-1} \\mid \\mathbf{x}<em>t\\right)}{q\\left(\\mathbf{x}<em>t \\mid \\mathbf{x}</em>{t-1}\\right)}-\\log \\frac{p</em>\\theta\\left(\\mathbf{x}_0 \\mid \\mathbf{x}_1\\right)}{q\\left(\\mathbf{x}_1 \\mid \\mathbf{x}<em>0\\right)}\\right] \\<br>\n&amp;=\\mathbb{E}<em>q\\left[-\\log p\\left(\\mathbf{x}<em>T\\right)-\\sum</em>{t&gt;1} \\log \\left[\\frac{p</em>\\theta\\left(\\mathbf{x}</em>{t-1} \\mid \\mathbf{x}<em>t\\right)}{q\\left(\\mathbf{x}</em>{t-1} \\mid \\mathbf{x}_t, \\mathbf{x}<em>0\\right)} \\cdot \\frac{q\\left(\\mathbf{x}</em>{t-1} \\mid \\mathbf{x}_0\\right)}{q\\left(\\mathbf{x}_t \\mid \\mathbf{x}<em>0\\right)}\\right]-\\log \\frac{p</em>\\theta\\left(\\mathbf{x}_0 \\mid \\mathbf{x}_1\\right)}{q\\left(\\mathbf{x}_1 \\mid \\mathbf{x}_0\\right)}\\right]<br>\n\\end{aligned}<br>\n\\end{equation}$</p>\n<p>倒数两步的变换发生在第二项，具体依据为：<br />$\\begin{align}<br>\nq\\left(\\mathbf{x}<em>t \\mid \\mathbf{x}</em>{t-1}\\right)<br>\n=&amp; \\frac{q\\left(\\mathbf{x}<em>t, \\mathbf{x}</em>{t-1}\\right)}{q\\left(\\mathbf{x}<em>{t-1}\\right)} \\<br>\n=&amp; \\frac{q\\left(\\mathbf{x}<em>t, \\mathbf{x}</em>{t-1} \\mid \\mathbf{x}</em>{0}\\right) *q(\\mathbf{x}<em>{0})}{q\\left(\\mathbf{x}</em>{t-1} \\mid \\mathbf{x}<em>{0}\\right) * q(\\mathbf{x}</em>{0})} \\<br>\n=&amp; \\frac{q\\left(\\mathbf{x}<em>t, \\mathbf{x}</em>{t-1} \\mid \\mathbf{x}<em>{0}\\right) }{q\\left(\\mathbf{x}</em>{t-1} \\mid \\mathbf{x}<em>0\\right)}<br>\n\\end{align}<br>\n\\quad \\Rightarrow \\quad<br>\n\\begin{align}<br>\n&amp;\\sum</em>{t&gt;1} \\log \\frac{p_\\theta\\left(\\mathbf{x}<em>{t-1} \\mid \\mathbf{x}<em>t\\right)}{q\\left(\\mathbf{x}<em>t \\mid \\mathbf{x}</em>{t-1}\\right)} \\<br>\n=&amp; \\sum</em>{t&gt;1} \\log \\frac{p</em>\\theta\\left(\\mathbf{x}<em>{t-1} \\mid \\mathbf{x}<em>t\\right)}{q\\left(\\mathbf{x}<em>t, \\mathbf{x}</em>{t-1} \\mid \\mathbf{x}</em>{0}\\right) } \\cdot {q\\left(\\mathbf{x}</em>{t-1} \\mid \\mathbf{x}<em>0\\right)} \\<br>\n=&amp; \\sum</em>{t&gt;1} \\log \\frac{p_\\theta\\left(\\mathbf{x}_{t-1} \\mid \\mathbf{x}<em>t\\right)}{q\\left(\\mathbf{x}</em>{t-1} \\mid \\mathbf{x}_t, \\mathbf{x}<em>0\\right)} \\cdot \\frac{q\\left(\\mathbf{x}</em>{t-1} \\mid \\mathbf{x}_0\\right)}{q\\left(\\mathbf{x}_t \\mid \\mathbf{x}_0\\right)}<br>\n\\end{align}$</p>\n<p>接着对$(5)$进行改写得到最终形式$(6)$：<br />$\\begin{equation}<br>\n\\begin{align}<br>\nL &amp;=\\mathbb{E}_q\\left[-\\log \\frac{p\\left(\\mathbf{x}<em>T\\right)}{q\\left(\\mathbf{x}<em>T \\mid \\mathbf{x}<em>0\\right)}-\\sum</em>{t&gt;1} \\log \\frac{p</em>\\theta\\left(\\mathbf{x}</em>{t-1} \\mid \\mathbf{x}<em>t\\right)}{q\\left(\\mathbf{x}</em>{t-1} \\mid \\mathbf{x}<em>t, \\mathbf{x}<em>0\\right)}-\\log p</em>\\theta\\left(\\mathbf{x}<em>0 \\mid \\mathbf{x}<em>1\\right)\\right] \\<br>\n&amp;=\\mathbb{E}<em>q[\\underbrace{D</em>{\\mathrm{KL}}\\left(q\\left(\\mathbf{x}<em>T \\mid \\mathbf{x}<em>0\\right) | p\\left(\\mathbf{x}<em>T\\right)\\right)}</em>{L_T}+\\sum</em>{t&gt;1} \\underbrace{D</em>{\\mathrm{KL}}\\left(q\\left(\\mathbf{x}</em>{t-1} \\mid \\mathbf{x}<em>t, \\mathbf{x}<em>0\\right) | p</em>\\theta\\left(\\mathbf{x}</em>{t-1} \\mid \\mathbf{x}<em>t\\right)\\right)}</em>{L</em>{t-1}} \\underbrace{-\\log p</em>\\theta\\left(\\mathbf{x}_0 \\mid \\mathbf{x}<em>1\\right)}</em>{L_0}]<br>\n\\end{align}<br>\n\\end{equation}$<br>\n<a name=\"y8x7s\"></a></p>\n<h1>Summary</h1>\n<p>太好了，对于$(6)$来说，它最起码是个可以优化的目标函数了，因为论文中定义马尔可夫链相邻状态的转变是服从高斯分布的。当然在论文中，$(6)$还会进一步被改写，最后得到更加精简的$\\text{loss function}$的形式。本文主要还是基于<code>DDPM</code>，对$\\text{variational inference}$的一些学习。<br>\n<a name=\"SWBBd\"></a></p>\n<h1>Reference</h1>\n<ul>\n<li><a href=\"https://www.youtube.com/playlist?list=PLyAft-JyjIYoN_6X932U_-ZlHKdInFrUV\">Variational Inference Basic, Xu, R.Y.D</a></li>\n<li><a href=\"https://arxiv.org/abs/2006.11239\">Denoising Diffusion Probabilistic Models</a></li>\n</ul>\n","tags":["Diffusion Model","Math Heavy"]}]